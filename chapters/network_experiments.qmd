# Network experiments

- Network experiments are experiments where there the treatment status of units might determine the outcome of other units, thus violating the [SUTVA assumption](neyman_rubin_causal_model.qmd## Stable unit treatment value assumption (SUTVA)
)

- @larsen2023statistical cite a large number of papers that provide more details on these approaches and provide solutions to some of the challenges.


## The problem

- Interference creates bias in standard ATE estimators.

- Fundamentally, this happens because with interference, the ATE is not an estimate of what would happen if all units were treated (which is what standard ATE estimates are estimating).


## Types of interferance

@larsen2023statistical differentiate between:

- Network interference: all units in the population are the same but they interact with each other. In particular, interference happens when the treatment status of users in a social network mutually determines their outcome (e.g. one user being assigned to a new messenger service might increase messaging for that individual's friends who are in control)

- Marketplace interference: there are at least two types of units that form an online marketplace (i.e. sellers and buyers), and interference often happens when units compete for finite resources (e.g. uber customers hailing a finite amount of drivers, JET restaurants relying on a finite number of drivers). Examples are ride hailing, job matching, ads marketplaces, education platforms, and food delivery, which is an example of a three-sided marketplace. 

- A particular typs of interference is "cannibalisation", whereby the increase in the desired behaviour in the treatment group is solely or (under partial cannibalisation) partially due to a shift of the behaviour from control units to treatment units. This usually happens if units share a common pool of a fixed resource (e.g. a fixe number of uber drivers, a fixed number of items to buy at an auction) and the treatment makes it easier or more attractive for the treatment units to engage in the behaviour, which then leaves fewer resources to the control. In other words, it's in zero-sum contexts. See @liu2020trustworthy


## Dealing with interaction effects

- There are a number of different approaches (see, e.g. discussion in @larsen2023statistical)

- What they share in common is that they all address the fundamental problem: that units that interact with one another are not all in the same treatment group, as they would be if everyone were in the same treatment group (as standard ATE estimaors assume).

- There are two broad approaches: those that adjust the design, and those that adjust the analysis.


### Design-based approaches

#### Cluster-based randomisation approaches

- This approache first splits the units into clusters that are disjoint (or as disjoint as possible). Randomisation then happens at the cluster level, and all units within a cluster receive the same treatment.

- Because units will interact only (or mostly) with units that have the same treatment status as they themselves, this design provides a better counterfacturals for the all-treated and all-controlled alternatives.

- One challenge is creating clusters: effectively, you need to find the clusters between which there is no interactions, so that externalities don't spill across cluster boundaries. Examples:

  - Geographical clustering:

    - to experiment on currier behaviour in a food delivery network: randomise at a level at which curriers don't interact (such as a part of a large city, or even between cities).

    - In a online-dating network, clusters may be geographical regions between which there is little interaction between users (i.e. locations to far away for people to wanting to find partners)

  - social/interaction-graph-clustering:

    - To test a feature in a social-network app: create graphs of user interactions, and partition the graph such that there is maximal within-group interaction and minimal between group interaction

- Another challenge is ensuring you have enough effective sample size: if the outcomes of users within a group are correlated, then randomising at a level higher than the unit reduces effective sample size. In the extreme case, where within group correlation is perfect, your effective sample size is the number of groups, not the number of units.

#### Ego-clusters

- Instead of traditional clusters, create much smaller, unit-based clusters.

#### Switchback experiments

- An approach often used to deal with marketplace interferance, whereby all units are frequently switched from being in control to being in treatment.

- There could be carry-over issues with this, but this can be dealt with by using "burn-in" periods.

- Another issue is that, like cluster-randomisation, switchbacks also suffer from lower power.


### Analysis-based approaches

- Analysis based approaches model the interference and then adjust the analysis accordingly. See last paragraph of section 6 in @larsen2023statistical for details.


## Measuring interaction effects

- Overall approach: if there are no interaction effects, different estimands should be the same

- Design side: run clauster and unit-level experiment side-by-side. Different results imply presence of interaction effects

- Analysis side: 1) exposure modelling / reweighting 2) use of focal units


## Useful resources

- @larsen2023statistical, in section 6, provides a recent review of the literature.

- @karrer2021network describe network experimentation at Meta.

