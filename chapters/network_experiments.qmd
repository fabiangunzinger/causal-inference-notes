# Network experiments

- Network experiments are experiments in a context in which the outcome of some units is affected by the treatment status of other units, so that the treatment may not only change the behaviour of treated untis but also that of control units.

- This violates [SUTVA](neyman_rubin_causal_model.qmd## Stable unit treatment value assumption (SUTVA)) and leads to a bias in standard ATE estimators. 

- Fundamentally, we're dealing with a threat to external validity. In general, external validity is about the extent to which results from a scientific study can be generalised to contexts outside of the study. In the context of online experiments, where we typically experiment on a sample of the overall user population, external validity is about the extent to which results from our experiments translate to the entire population of users. Standard ATE estimators estimate the difference between two counterfactual states of the world: that where all units are treated and that which no units are treated. With interference, control units behave differently than they would have if nobody had been exposed to the treatment (and treatment of the treted units hadn't spilled over to them), and so the difference in treatment and control outcomes is no longer an unbiased estimate of the difference in outcomes of these two counterfactual states of the world.

## Types of interferance

@larsen2023statistical differentiate between:

- Network interference. Suppose we have a network where all nodes are of the same type and where the behaviour of each node can affect the behaviour of the nodes it is directly connected to. An example is a social network, where all nodes are people, and where more activity of one person may plausibly lead to more activity among their connections, which may lead to more activity among their connections, and so on. Here, experimentation is difficult because if we randomly split units into treatment and control group, units in the treatment group that change their behaviour as a result of the treatment might interact with connections of theirs that are allocated to the control group and thus change their behaviour as a result. But now the units in the control group don't behave any longer as they would under the absence of the treatment, and comparing the differences in behaviour between treatment and control is not an accurate representation of the different outcomes in two counterfactual states of the world, one where everyone is treated and one where nobody is.

- Marketplace interference. Suppose we have a network composed of two of more types of nodes which interact with each other, and where, from the perspective of each type of node, the number of other nodes is finite, so that each type of node competes for interactions with a fixed number of nodes of the other type. Examples include ride hailing, where drivers compete for customers and customers for available rides; ads marketplaces, where marketers compete for slots and platforms with slots for marketers; or food delivery services, where riders compete for orders and customers who place orders for riders (food delivery services, such as Deliveroo, are three-sided marketplaces, managing the interaction of restaurants, riders, and customers). In such a marketplace experimentation is challenging because treatment and control groups compete for a fixed pool of resources, so that an increase in behaviour for the treatment group must lead to a decrease in the decreate of the behaviour for the control group. This "cannibalisation" effect exaggerates the actual treatment effect. (See @liu2020trustworthy for more.)


## Dealing with interference

- There are a number of different approaches (see, e.g. discussion in @larsen2023statistical)

- What they share in common is that they all address the fundamental problem, which is that under the presence of interaction effects, the difference in outcomes between the treatment and the control group is not an accurate representation of the two counterfactual states of the world where everyone is and isn't exposed to the treatment, which is what standard ATE estimators measure.

- There are two broad ways to tackle the problem: we can adjust the design to limit interference in the first place, or we can model interference and adjust the analysis.

### Design-based approaches

#### Cluster-based randomisation approaches

- This approache first splits the units into clusters that are disjoint (or as disjoint as possible). Randomisation then happens at the cluster level, and all units within a cluster receive the same treatment.

- Because units will interact only (or mostly) with units that have the same treatment status as they themselves, this design provides a better counterfacturals for the all-treated and all-controlled alternatives.

- One challenge is creating clusters: effectively, you need to find the clusters between which there is no interactions, so that externalities don't spill across cluster boundaries. Examples:

  - Geographical clustering:

    - to experiment on currier behaviour in a food delivery network: randomise at a level at which curriers don't interact (such as a part of a large city, or even between cities).

    - In a online-dating network, clusters may be geographical regions between which there is little interaction between users (i.e. locations to far away for people to wanting to find partners)

  - social/interaction-graph-clustering:

    - To test a feature in a social-network app: create graphs of user interactions, and partition the graph such that there is maximal within-group interaction and minimal between group interaction

- Another challenge is ensuring you have enough effective sample size: if the outcomes of users within a group are correlated, then randomising at a level higher than the unit reduces effective sample size. In the extreme case, where within group correlation is perfect, your effective sample size is the number of groups, not the number of units. See 

- How to adjust standard errors? See @abadie2023should and @de2024level


#### Ego-clusters

- Instead of traditional clusters, create much smaller, unit-based clusters. See @saint2019using


#### Switchback experiments

- An approach often used to deal with marketplace interferance, whereby all units are frequently switched from being in control to being in treatment.

- There could be carry-over issues with this, but this can be dealt with by using "burn-in" periods.

- Another issue is that, like cluster-randomisation, switchbacks also suffer from lower power.


### Analysis-based approaches

- Analysis based approaches model the interference and then adjust the analysis accordingly. See last paragraph of section 6 in @larsen2023statistical for details. Also, @bojinov2023design, in their introduction, differentiate between approaches that rely on game theoretic, Markov Chain, and network approachs to model interference.


## Measuring interaction effects

- Overall approach: if there are no interaction effects, different estimands should be the same

- Design side: run clauster and unit-level experiment side-by-side. Different results imply presence of interaction effects

- Analysis side: 1) exposure modelling / reweighting 2) use of focal units


## Useful resources

- @larsen2023statistical, in section 6, provides a recent review of the literature.

- @karrer2021network describe network experimentation at Meta.

