# Metrics

The choice of metrics to consider when evaluating an experiment is not trivial. In field experiments, collecting data can be very costly, which puts an automatic limit to the number of metrics collected. In online experiments, the number of metrics we could look at is vast.

## Types of metrics

- Northstar -- company wide, directly aligned with mission, the one metric that best represents how company creates value for its customers

    - Amazon example: avg monthly purchases per user

- Primary -- capture goal of particular team/product/initiative

    - Amazon buyer focused team: number of high-quality sellers that join platform per month.

- Supporting/Tracking/Input -- indicators that the primary or NS metric are moving in the right direction (particularly useful as leading indicators)

  - Amazon example: emails sent to HQ sellers, emails opened, 

- Guardrail: ensures that improvements in primary metrics don't come at the cost of quality/experience/something else -- basically to avoid unintended consequences

    - Amazon example: average number of purchases per day (to check that influx of sellers doesn't lead to paralysis for buysers)


## What makes a good Metric

- Meaningful (reflect goals of company, product)
- Measurable ()
- Moveable (with low delay)
- Interpretable (not too complicated, easy to communicate and understand)
- Not gameable (violate Goodhart's law)


## How to select metrics

- NSM and primary based on main company/product goal, focus on criteria above

- Support and guardrails trickier. Use AAAERRR Framework


## AAAERRR

- Awareness (how many aware of product)

- Acquisition (how many use product)

- Activation (how many are realizing value of product -- e.g. 10 friends in 7 days on FB / stored at least 1 file on a device on Dropbox)

- Engagement (breath and frequencey of engagement)

- Revenue (how many are paying for product)

- Retention/renewal (how many are coming back)

- Referral (how many are becoming advocates)



todo


- Look at Spotify confidence

- Primary metric something that directly captures what you wanna improve? Guardrails general health metrics you don't want to go down (e.g. revenue, conversion)? Based on Kohavi anecdote below

- @bojinov2020importance mention that LinkedIn has four company wide success metrics and many product specific ones. So, presumably we'd use company-wide ones as guardrails. Question is, what are good product-specific metrics? Good in the sense that they have a positive impact on business-wide metrics? Can use causal inference (e.g. IV) to test effect (see section 2.1 in @bojinov2020importance)


## Common metrics

- Conversion rate
- Number of bookings
- Engagement
  - Likes, shares, comments, reactions
  - Page views
  - Click-through rates (CTR)
  - Time spent per user per day

- Retention
  - Daily active users (DAU)
  - Churn rate (percentage of users who stop using the service within a given period)

- Revenue
  - Average revenue per user (ARPE)
  - Customer lifetime value (CLV)


Guardrail metrics
- Bounce rate (proportion of site visitors who leave after seeing only the first page)
- Cancellation rate
- 


## Ways to think about Metrics

- From Meta 
  - Topline metric: e.g. daily active users
  - Feature/product team northstar: e.g. total buyers for buyer-facing side of marketplace
  - Guardrail metric: number of messages flagges as spam or harmful in msg app



## Misc issues

- Selecting the wrong metric can lead to misleading results. @kohavi2012trusworthy provide a memorable example from an experiment at Bing: the experiment increased revenue by user because search results were poorer, leading users to make more searches and lead them to click on more adds. This is good in the short-term. But in the long term, users will surely get frustrated by the poorer search results. A better metric would have been one that directly captures the quality of the search results, such as sessions per user. Lesson: have a primary metric that directly captures the thing you want to improve. Use higher level-metrics such as revenue as guardrails.


## Useful resources

- [Defining Product Metricsâ€” The Ultimate Guide [Part 1 of 2](https://towardsdatascience.com/defining-product-metrics-the-ultimate-guide-part-1-of-2-585b8c63fcef)