# Fisher's exact P-value approach

These are my notes from reading chapter 5 in @imbens2015causal.

Fisher's aim in his original work on experimentation was to asses the *sharp (or exact) null hypothesis* -- the hypothesis that a treatment had no effect whatsoever, meaning that the potential outcomes for being treated and not treated are the same for each unit in the data.[^hypothesis]

Unter that null hypothesis, the unobserved potential outcomes are known -- they are the same as the observed outcome -- and we can use the randomisation distribution to calculate P-values. We can calculate P-values by calculating the test statistic for all possible assignments, and then calculate the probability that the test-statistic is as extreme or more extreme than the value of the test statistic in our experiment.

Let's look at an example. We have a sample of six units, three assigned to treatment ($w_i = 1$) and three to control ($w_i = 0$). For each of the six units the value we observe is the potential outcome corresponding to the treatment status.

|   | $y_i(0)$ | $y_i(1)$ | $w_i$ | $y_i^{obs}$ |
|---|----------|----------|-------|-------------|
| 1 | ?        | 3        | 1     | 3           |
| 2 | ?        | 5        | 1     | 5           |
| 3 | ?        | 0        | 1     | 0           |
| 4 | 4        | ?        | 0     | 4           |
| 5 | 0        | ?        | 0     | 0           |
| 6 | 1        | ?        | 0     | 1           |

This table highlights the fundamental problem of causal inference -- we can only ever observe one potential outcome for each unit.

However, Fisher's sharp null hypothesis asserts that:

$$
H_0: y_i(1) = y_i(0) \quad \text{for $i = 1, \dots, 6$},
$$

which makes filling in the missing values trivial:

|   | $y_i(0)$ | $y_i(1)$ | $w_i$ | $y_i^{obs}$ |
|---|----------|----------|-------|-------------|
| 1 | (3)        | 3        | 1     | 3           |
| 2 | (5)        | 5        | 1     | 5           |
| 3 | (0)        | 0        | 1     | 0           |
| 4 | 4        | (4)        | 0     | 4           |
| 5 | 0        | (0)        | 0     | 0           |
| 6 | 1        | (1)        | 0     | 1           |

There are a number of different test statistics we could use (and @imbens2015causal discuss and compare an number of them). Following the book, for this example I use the absolute value of the difference in average outcome by treatment status, $T(w, y^{obs}) = |\bar{y}_t^{obs} - \bar{y}_c^{obs}|$, which is a function of the random assignment $w$ and the observed values $y^{obs}$.

For our little experiment above, we can calculate the test statistic easily as:

$$
\begin{aligned}
T^{obs} &= |(y_1^{obs} + y_2^{obs} + y_3^{obs})/3 - (y_4^{obs} + y_5^{obs} + y_6^{obs})/3| \\
&= |(3 + 5 + 0)/3 - (4 + 0 + 1)/3| \\
&= 8/3 - 5/3 \\
&= 1
\end{aligned}
$$

To calculate the P-value, we need the distribution of test statistics under all possible random assignments. There are $\begin{psmallmatrix}6\\3\end{psmallmatrix} = 20$ different assignments, and we can calculate the distribution using Python:

```{python}
import numpy as np
from itertools import combinations
import seaborn as sns

y = np.array([3, 5, 0, 4, 0, 1])
idx = range(len(y))

ts = []
for w in combinations(idx, 3):
    w0, w1 = list(set(idx) - set(w)), list(w)
    y0, y1 = y[w0], y[w1]
    t = abs(np.mean(y1) - np.mean(y0))
    ts.append(t)

sns.histplot(ts);
```

With that distribution in hand, we can easily calculate the P-value:

```{python}
p = np.mean([t >= 1 for t in ts])
p
```

The P-value indicates that if there is no treatment effect, we'd expect a value of the test statistic equal to 1 or even larger in 50 out of 100 random experiments.


[^hypothesis] Compare this to the null hypothesis we more frequently test in experiments, namely, that there is no treatment effect on average. This later hypothesis is less strict (or sharp) than Fisher's, but arguably of more practical interest most of the time.


## Useful resources

@imbens2015causal