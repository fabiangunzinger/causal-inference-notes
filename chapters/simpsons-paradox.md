# Simpson's paradox

- Simpson's paradox happens due to a kind of omitted variable bias.

- It can occur if pooling data overlooks a confounding driver of the data generation that affects the data in specific ways.

- In particular, the underlying data needs to be such that the confounding group is both related to the composition of units and their outcomes.

Examples:

- Women appear to have lower acceptance rates at Berkeley than men because they disproportionally apply to departments with lower acceptance rates.

- A medication appears to harm patients overall even though it benefits each subgroup because it is only given to patients who are very sick.

- Wisconsin outperforms Texas in standardised test scores but underperforms when looking at each socioeconomic group separately because Texas has more students from disadvantaged socioeconomic groups.


- The paradox has two classic manifestations: frequency Tables and correlations.

- For frequency Tables, classic examples are listed on [Wikipedia](https://en.wikipedia.org/wiki/Simpson%27s_paradox#Examples). Notice that in all the examples, the difference in outcomes between levels of the confounder (departments, stone size, and year) is much larger than the differences between the groups of interest (men and women, treatments, batters) at any given level of the confounder.

- For correlations, the below gif makes things very clear.

![Pace~svwiki, CC BY-SA 4.0 <https://creativecommons.org/licenses/by-sa/4.0>, via Wikimedia Commons](../inputs/simpsons_paradox.gif)


- The above definition makes clear that it's only a problem if there is an omitted variable that drives both assignment and outcome.

- Hence, as a corollary, in a random experiment, where treatment assignment is random, changing allocation proportions isn't an issue if assignment is truly random throughout.


## Q&A

Questions

1. 



Answers

1. 
