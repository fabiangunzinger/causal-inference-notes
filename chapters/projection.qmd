# Projection

A projection is a transformation of a vector onto a subspace.[^subspace]

There are different types of projections, but the one that's relevant for us here is *orthogonal projection*, which projects a vector onto the nearest point on the subspace, where "nearest" usually refers to the Euclidean distance. Why this type of projection is called "orthogonal projection" will be come clear below.

Content:

- Projection onto 1-D
- Projection onto 2-D and N-D
  - Exlain why projection is useful


## Projection onto 1-D

Projecting a vector in two-dimensional space onto a line through the origin is a nice way to build an understanding for what a projection does.[^line]

Say we want to orthogonally project the vector $b$ onto the line $a$, and we will call the resulting projection $p$. Hence, $p$ is the point on $a$ that is nearest to the (tip of) the vector $b$. We can think of the line $a$ as a base vector $a$ and a scalar, $x$, so that choosing a suitable $x$ allows us to reach any point on the line. Finding $p$ then boils down to finding the value of $x$ that gets us to that point of the line $a$ that is closest to $b$.

We can find $p$ in different ways.

Using calculus:

Minimising the distance between the (tip of) the vector, $b$, and the projection, $p$,  is akin to solving the following problem:

$$
\begin{aligned}
argmin_{x} \sqrt{\sum_{i=1}^2{(b_i - p_i)^2}} &= argmin_{x} \sum_{i=1}^2{(b_i - p_i)^2} \\
&= argmin_{x} \sum_{i=1}^2{(b_i - xa_i)^2} \\
&= argmin_{x} (b - xa)'(b - xa) \\
\end{aligned}
$$

Setting the derivative with respect to $x$ to zero we get:

$$
\begin{aligned}
\frac{d}{dx} (b - xa)'(b - xa) &= (-a)'(b - xa) + (b - xa)'(-a) & \\
&= -a'b + xa'a - a'b + xa'a \\
&= -2a'b + 2xa'a = 0
\end{aligned}
$$

Solving for $x$ we get:

$$
\begin{aligned}
-2a'b + 2xa'a &= 0 \\
xa'a &= a'b \\
x &= (a'a)^{-1}a'b
\end{aligned}
$$

Hence, given that $p = ax$, we have:

$$
\begin{aligned}
p = ax = \underbrace{a(a'a)^{-1}a'}_\text{$P_a$}b,
\end{aligned}
$$

where $P_a$ is the projection matrix.

So, what is going on here? In general, pre-multiplying a vector by a matrix transforms the vector to the vector space spanned by the matrix. In our case here, pre-multiplying our initial vector $b$ by the matrix $P_a$ transforms $b$ onto the subspace spanned by $a$, and does this in a very particular way: it transforms $b$ into the point on $a$ that is closest to $b$. 





[todo: insert figure here]





## Footnotes

[^subspace]: A subspace is a subset of a vector space that is itself a vector space in which any possible linear combination of two vectors in the space is also in the space. For instance, a 2-dimensional plane is a subspace of $\mathbb{R}^3$ if it contains all possible linear combinations of any 2-dimensional vectors. For this to be the case, the plane has to go through the origin -- the point (0, 0, 0) -- to contain linear combinations with the zero scalar. Similarly, a line that goes through the origin is also a valid subspace, since any linear combination of two vectors that lie on the line will also lie on the line.

[^line]: A line through the origin is a subspace of a two-dimensional vector because it is 1-dimensional (and thus a subset of the 2-dimensional vector space) and because all possible linear combinations of vectors on the line will also lie on the line (see discussion on subspace above).




$$
\begin{aligned}
\alpha &= \beta \\
&= \delta
\end{aligned}
$$

```sh
python -m pip install rosalie
```

```{python}
import pandas as pd
df = pd.DataFrame({'a': [1, 2, 3]})
df.head()
```


## References

- Strang linalg lectures