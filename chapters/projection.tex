% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[interior hidden, boxrule=0pt, borderline west={3pt}{0pt}{shadecolor}, frame hidden, breakable, sharp corners, enhanced]}{\end{tcolorbox}}\fi

\hypertarget{sec-projection}{%
\section{Projection}\label{sec-projection}}

A projection is a transformation of a vector onto a subspace.\footnote{A
  subspace is a subset of a vector space that is itself a vector space
  in which any possible linear combination of two vectors in the space
  is also in the space. For instance, a 2-dimensional plane is a
  subspace of \(\mathbb{R}^3\) if it contains all possible linear
  combinations of any 2-dimensional vectors. For this to be the case,
  the plane has to go through the origin -- the point (0, 0, 0) -- to
  contain linear combinations with the zero scalar. Similarly, a line
  that goes through the origin is also a valid subspace, since any
  linear combination of two vectors that lie on the line will also lie
  on the line.}

There are different types of projections, but the one that's relevant
for us here is \emph{orthogonal projection}, which projects a vector
onto the nearest point on a subspace, where ``nearest'' usually refers
to the Euclidean distance.\footnote{The Euclidean distance between two
  points \(x\) and \(\bar{x}\) in \(\mathbb{R}^N\) is defined as
  \(\sqrt{\sum_{i=1}^N{(\bar{x_i} - x_i})^2}\).} Why this type of
projection is called ``orthogonal projection'' will be come clear below.

\hypertarget{projecting-from-2-d-onto-1-d}{%
\subsection{Projecting from 2-D onto
1-D}\label{projecting-from-2-d-onto-1-d}}

Projecting a vector in two-dimensional space onto a line that goes
through the origin is a nice way to build an understanding for what a
projection does.\footnote{A line through the origin is a subspace of a
  two-dimensional vector because it is 1-dimensional (and thus a subset
  of the 2-dimensional vector) and because all possible linear
  combinations of vectors on the line will also lie on the line (the
  line needs to pass through the origin for this latter statement to be
  true, see the footnote on subspaces).}

Say we want to orthogonally project the vector \(b\) onto a line defined
by another vector, \(a\), and we will call the resulting projection
\(p\). Hence, \(p\) is the point on the line defined by \(a\) that is
nearest to the (tip of) the vector \(b\).

We can think of the line as being generated by scaling vector \(a\) with
a scalar \(x\), so that choosing a suitable \(x\) allows us to reach any
point on the line. Finding \(p\) then boils down to finding the value of
\(x\) that gets us to that point of the line that is closest to \(b\).
We can thus write \(p = ax\).

{[}todo: insert figure here{]}

Let's start by finding \(p\). We can find it in different ways.

\textbf{Using calculus}:

Minimising the distance between the (tip of) the vector, \(b\), and the
projection, \(p\), is akin to solving the following problem:

\[
\begin{aligned}
argmin_{x} \sqrt{\sum_{i=1}^2{(b_i - p_i)^2}} &= argmin_{x} \sum_{i=1}^2{(b_i - p_i)^2} \\
&= argmin_{x} \sum_{i=1}^2{(b_i - xa_i)^2} \\
&= argmin_{x} (b - xa)'(b - xa),
\end{aligned}
\]

Calculating the derivative with respect to \(x\) to zero we get:

\[
\begin{aligned}
\frac{d}{dx} (b - xa)'(b - xa) &= (-a)'(b - xa) + (b - xa)'(-a) & \\
&= -a'b + xa'a - a'b + xa'a \\
&= -2a'b + 2xa'a = 0
\end{aligned}
\]

Solving for \(x\) we get:

\[
\begin{aligned}
-2a'b + 2xa'a &= 0 \\
xa'a &= a'b \\
x &= (a'a)^{-1}a'b
\end{aligned}
\]

Hence, given that \(p = ax\), we have:

\[
\begin{aligned}
p = ax = \underbrace{a(a'a)^{-1}a'}_\text{$P_a$}b,
\end{aligned}
\]

where \(P_a\) is the projection matrix.

Let's reflect for a moment what this all means. In general,
pre-multiplying a vector by a matrix transforms the vector in a
particular way. When we perform orthogonal projection, we pre-multiply a
vector by a matrix that transforms the vector into that point on a
subspace that it closest to the original vector. In our case here,
pre-multiplying our initial vector \(b\) by the projection matrix
\(P_a\) transforms \(b\) into that point on \(a\) that is closest to
\(b\), which we call \(p\). Given that we define ``nearest'' using the
Euclidean distance, it makes sense that the projection matrix would
emerge out of the solution to the minimisation problem of finding the
point on the subspace that minimises the Euclidean distance to the
original vector.

\textbf{Using basic geometry:}

We could also find \(p\) using our understanding of basic geometry.
Looking at the figure above, it is intuitively obvious that the shortest
path between the tip of \(b\) and the projection \(p\) onto \(a\) is
that which is perpendicular to the line \(a\). The path between \(b\)
and \(p\) is simply \(b - p\). In linear algebra terms, we thus want
that path to be orthogonal to the line \(a\).\footnote{TODO explain
  concept of orthogonality and why it is equivalent to the dot-product
  being zero.}

Hence, we want:

\[
\begin{aligned}
a'(b - p) &= 0 \\
a'(b - xa) &= 0 \\
a'b - xa'a &= 0 \\
xa'a &= a'b \\
x &= (a'a)^{-1}a'b
\end{aligned}
\]

So that, again, we have:\footnote{TODO show what happens if we define
  \(p = xa\) instead of \(p = ax\)}

\[
p = ax = \underbrace{a(a'a)^{-1}a'}_\text{$P_a$}b.
\]

This also makes clear why this type of projection is called ``orthogonal
projection'': we want to project a vector onto a subspace in such a way
that the distance between the original vector and the subspace is
minimal. The resulting projection will be a point on the suspace such
that a vector from that point to the original vector is orthogonal to
the subspace. Intuitively, this is the case because the shortest path
between the vector and the subspace will be that which is perpendicular
to the subspace, and orthogonality is the generalisation of the notion
of perpendicularity.

\hypertarget{why-project}{%
\subsection{Why project?}\label{why-project}}

Projection is useful because it allows us to approximately solve systems
of linear equations that have no exact solution. Imagine we have the
following system of equations:

\[
\begin{align*}
a_{11}x_1 + a_{12}x_2 + \cdots + a_{1k}x_k &= b_1 \\
a_{21}x_1 + a_{22}x_2 + \cdots + a_{2k}x_k &= b_2 \\
\vdots \\
a_{n1}x_1 + a_{n2}x_2 + \cdots + a_{nk}x_k &= b_n
\end{align*}
\]

which we can write more compactly in matrix form as:

\[
Ax = b.
\]

If \(n > k\), the system is overdetermined -- it has more constarints
(equations) than degrees of freedom (variables) -- and might not have a
solution. In this case, it can be useful to solve

\[
Ax = \hat{b},
\]

where \(\hat{b}\) is the orthogonal projection of \(b\) onto the vector
space spanned by \(A\), called the span or column space of \(A\). Using
orthogonal projection in this case achieves two things: it guarantees a
solution because \(\hat{b}\) lies on the same space as \(Ax\) -- they
both lie on the subspace spanned by the columns of \(A\) -- and is makes
\(\hat{p}\) the best approximation to \(b\) in that it is closest to it
in terms of the Euclidean distance.

\hypertarget{projection-from-3-d-onto-2-d-and-projecting-onto-n-d}{%
\subsection{Projection from 3-D onto 2-D and projecting onto
N-D}\label{projection-from-3-d-onto-2-d-and-projecting-onto-n-d}}

Our starting point is similar to the 2-D onto 1-D example above, but our
vector \(b\) is now 3-dimensional and the subspace we project it onto is
now not a 1-dimensional line but a 2-dimensional plane. Hence, \(p\) is
now a point in the 3-dimensional space that lies on the 2-dimensional
subspace. Above, we defined \(p\) as \(p = ax\), where \(a\) was the
scalar that characterised the line and \(x\) the scalar that helped us
move along that line. Similarly, we now have \(p = Ax\), where \(A\) is
a 2 x 2 matrix, the two columns of which are the base vectors of the
2-dimensional subspace.

We can still go about finding \(p\) in the same way as above:

\[
\begin{aligned}
argmin_{x} (b - Ax)'(b - Ax) \\
\frac{d}{dx} (b - Ax)'(b - Ax) &= -2A'(b - Ax) = 0
\end{aligned}
\]

Solving for \(x\) we get: \[
\begin{aligned}
-2A'(b - Ax) &= 0 \\
-A'b + A'Ax &= 0 \\
A'Ax &= A'b \\
x &= (A'A)^{-1}A'b
\end{aligned}
\]

The last step above works only if \(A'A\) is actually invertible, which
is the case if \(A\) has full rank, which is the case if none of its
columns can be constructed from a linear combination of any other
columns. (A visual way to think about this is the following: the columns
of a matrix are the basis vectors of its column space. The rank is the
number of dimensions of that column space. Full rank means that the
column space has as many dimensions as there are columns.)

The math above generalises directly to projections onto N-dimensional
space. All that changes is that \(b\), \(A\), \(x\), and \(p\) are
higher-dimensional objects, and that visualising what's happening
becomes rather mind-bending.

\hypertarget{useful-references}{%
\subsection{Useful references}\label{useful-references}}

\begin{itemize}
\item
  \href{https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/video_galleries/video-lectures/}{Gilbert
  Strang's linear algebra lectures at MIT}
\item
  \href{https://bookdown.org/ts_robinson1994/10EconometricTheorems/linear_projection.html\#linear_projection}{10
  Fundamental Theorems for Econometrics}
\end{itemize}



\end{document}
