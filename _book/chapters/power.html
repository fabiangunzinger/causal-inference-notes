<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Causal inference notes - 3&nbsp; Power</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/projection.html" rel="next">
<link href="../chapters/stats_foundations.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
</head><body class="nav-sidebar floating"><span class="math inline">
    \(
    \newcommand{\nc}{\newcommand}

    %%%%%%%%%%%%%%%%
    % sample sizes %
    %%%%%%%%%%%%%%%%

    \nc{\Nt}{N_t}
    \nc{\Nc}{N_c}
    \nc{\N}{N}
    
    % outcomes
    \nc{yio}{Y_i^{obs}}
    \nc{ytp}{Y_i(1)}
    \nc{ycp}{Y_i(0)}
    \nc{\yto}{Y_t^{obs}}
    \nc{\yco}{Y_c^{obs}}
    \nc{ytpb}{\bar{Y}(1)}
    \nc{ycpb}{\bar{Y}(0)}
    \nc{\ytob}{\bar{Y}_t^{obs}}
    \nc{\ycob}{\bar{Y}_c^{obs}}

    % sums of outcomes

    % treatment effects
    \nc{\te}{\tau}
    \nc{\tee}{\hat{\te}}   
    \nc{\tef}{\ytpb - \ycpb}
    \nc{\teef}{\ytob - \ycob}
    \nc{\tefs}{\frac{1}{\N}\sum_{i=1}^N\left(\ytp-\ycp\right)}

    
    % sample variances

    \nc{\spv}{\sigma}   %symbol pop var
    \nc{\sev}{\hat{\sigma}}   %symbol estimated var

    \nc{\vt}{\spv^2_t}
    \nc{\vc}{\spv^2_c}
    \nc{\vp}{\spv^2}
    \nc{\vte}{\sev^2_t}
    \nc{\vce}{\sev^2_c}
    \nc{\vpe}{\sev^2}
    \nc{\vtf}{\frac{1}{\N-1}\sum_{i=1}^{N}(\ytp - \ytpb)^2}
    \nc{\vcf}{\frac{1}{\N-1}\sum_{i=1}^{N}(\ycp - \ycpb)^2}
    \nc{\vtef}{\frac{1}{\Nt-1}\sum_{i:W_i=t}(\yto - \ytob)^2}
    \nc{\vcef}{\frac{1}{\Nc-1}\sum_{i:W_i=c}(\yco - \ycob)^2}

    %%%%%%%%%%%%%%%%%%%%%%
    % sampling variances %
    %%%%%%%%%%%%%%%%%%%%%%

    % sv[Estimate][Formula][Equal/Unequal][with treat Proportion]

    \nc{\sv}{V(\te)}
    \nc{\sve}{\hat{V}(\tee)}

    \nc{\svfe}{\vp\left(\frac{1}{\Nt} + \frac{1}{\Nc}\right)}
    \nc{\svfu}{\frac{\vt}{\Nt} + \frac{\vc}{\Nc}}
    \nc{\svefe}{\vpe\left(\frac{1}{\Nt} + \frac{1}{\Nc}\right)}
    \nc{\svefu}{\frac{\vte}{\Nt} + \frac{\vce}{\Nc}}

    \nc{\svefep}{\vpe\left(\frac{1}{P(1-P)\N\right)}}


    %%%%%%%%%%%%%%%%%%%
    % standard errors %
    %%%%%%%%%%%%%%%%%%%

    % naming convention as for variance but with se prefix

    \nc{\se}{\text{se}(\te}
    \nc{\see}{\text{se}(\tee)}

    \nc{\sefe}{\sigma \sqrt{\frac{1}{\Nt} + \frac{1}{\Nc}}}
    \nc{\sefu}{\sqrt{\frac{\vt}{\Nt} + \frac{\vc}{\Nc}}}
    \nc{\seefe}{\sev\sqrt{\left(\frac{1}{\Nt} + \frac{1}{\Nc}\right)}}
    \nc{\seefu}{\sqrt{\frac{\vt}{\Nt} + \frac{\vc}{\Nc}}}

    <!-- \nc{\seefep}{\sev\sqrt{\left(\frac{1}{P(1-P)\N\right)}}} -->
    \nc{\seefep}{\sev\sqrt{\frac{1}{P(1-P)N}}}


    %%%%%%%%%%%%%%%%%%%%%%
    % hypothesis testing %
    %%%%%%%%%%%%%%%%%%%%%%

    \nc{hn}{H_0}
    \nc{ha}{H_A}
    \nc{za}{z_\alpha}
    \nc{zk}{z{1 - \kappa}}


    %%%%%%%%%%%%%%%%%%
    % other commands %
    %%%%%%%%%%%%%%%%%%

    \)
</span>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>





<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/power.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Power</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Causal inference notes</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">index.html</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/stats_foundations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Statistics foundation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/power.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Power</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/projection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Projection</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/fisher.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Fisher’s exact P-value approach</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/neyman.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Neyman’s repeated sampling approach</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/experiment_stats.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Statistics of online experiments</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/experiment_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Experiment analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/experiment_design.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Experiment design</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/metrics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Metrics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/threats_to_validity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Threats to validity</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/practical_issues.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Practical issues</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/network_experiments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Network experiments</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/ethics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Ethics</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#understanding-the-formula-that-determines-sample-size" id="toc-understanding-the-formula-that-determines-sample-size" class="nav-link active" data-scroll-target="#understanding-the-formula-that-determines-sample-size"><span class="header-section-number">3.1</span> Understanding the formula that determines sample size</a></li>
  <li><a href="#implications-of-the-formula" id="toc-implications-of-the-formula" class="nav-link" data-scroll-target="#implications-of-the-formula"><span class="header-section-number">3.2</span> Implications of the formula</a></li>
  <li><a href="#rules-of-thumb-the-big-16-vs-32-confusion" id="toc-rules-of-thumb-the-big-16-vs-32-confusion" class="nav-link" data-scroll-target="#rules-of-thumb-the-big-16-vs-32-confusion"><span class="header-section-number">3.3</span> Rules of thumb – the big 16 vs 32 confusion</a></li>
  <li><a href="#different-types-of-metrics" id="toc-different-types-of-metrics" class="nav-link" data-scroll-target="#different-types-of-metrics"><span class="header-section-number">3.4</span> Different types of metrics</a></li>
  <li><a href="#power-for-quasi-experimental-studies" id="toc-power-for-quasi-experimental-studies" class="nav-link" data-scroll-target="#power-for-quasi-experimental-studies"><span class="header-section-number">3.5</span> Power for quasi-experimental studies</a></li>
  <li><a href="#deriving-the-sample-size-formula" id="toc-deriving-the-sample-size-formula" class="nav-link" data-scroll-target="#deriving-the-sample-size-formula"><span class="header-section-number">3.6</span> Deriving the sample size formula</a>
  <ul class="collapse">
  <li><a href="#derivation-from-first-principles" id="toc-derivation-from-first-principles" class="nav-link" data-scroll-target="#derivation-from-first-principles"><span class="header-section-number">3.6.1</span> Derivation from first principles</a></li>
  <li><a href="#starting-from-type-i-and-type-ii-error-conditions" id="toc-starting-from-type-i-and-type-ii-error-conditions" class="nav-link" data-scroll-target="#starting-from-type-i-and-type-ii-error-conditions"><span class="header-section-number">3.6.2</span> Starting from Type I and Type II error conditions</a></li>
  <li><a href="#starting-from-graphical-illustration" id="toc-starting-from-graphical-illustration" class="nav-link" data-scroll-target="#starting-from-graphical-illustration"><span class="header-section-number">3.6.3</span> Starting from graphical illustration</a></li>
  </ul></li>
  <li><a href="#old-notes" id="toc-old-notes" class="nav-link" data-scroll-target="#old-notes"><span class="header-section-number">3.7</span> Old notes</a></li>
  <li><a href="#what-determines-power" id="toc-what-determines-power" class="nav-link" data-scroll-target="#what-determines-power"><span class="header-section-number">3.8</span> What determines power</a></li>
  <li><a href="#how-to-increase-power" id="toc-how-to-increase-power" class="nav-link" data-scroll-target="#how-to-increase-power"><span class="header-section-number">3.9</span> How to increase power</a></li>
  <li><a href="#how-to-choose-key-parameters" id="toc-how-to-choose-key-parameters" class="nav-link" data-scroll-target="#how-to-choose-key-parameters"><span class="header-section-number">3.10</span> How to choose key parameters</a>
  <ul class="collapse">
  <li><a href="#mde" id="toc-mde" class="nav-link" data-scroll-target="#mde"><span class="header-section-number">3.10.1</span> MDE</a></li>
  <li><a href="#significance-level" id="toc-significance-level" class="nav-link" data-scroll-target="#significance-level"><span class="header-section-number">3.10.2</span> Significance level</a></li>
  <li><a href="#power" id="toc-power" class="nav-link" data-scroll-target="#power"><span class="header-section-number">3.10.3</span> Power</a></li>
  </ul></li>
  <li><a href="#problems-with-low-power" id="toc-problems-with-low-power" class="nav-link" data-scroll-target="#problems-with-low-power"><span class="header-section-number">3.11</span> Problems with low power</a></li>
  <li><a href="#power-in-online-experiments" id="toc-power-in-online-experiments" class="nav-link" data-scroll-target="#power-in-online-experiments"><span class="header-section-number">3.12</span> Power in online experiments</a></li>
  <li><a href="#rule-of-thumb-for-sample-size" id="toc-rule-of-thumb-for-sample-size" class="nav-link" data-scroll-target="#rule-of-thumb-for-sample-size"><span class="header-section-number">3.13</span> Rule of thumb for sample size</a></li>
  <li><a href="#best-practices" id="toc-best-practices" class="nav-link" data-scroll-target="#best-practices"><span class="header-section-number">3.14</span> Best practices</a></li>
  <li><a href="#useful-resources" id="toc-useful-resources" class="nav-link" data-scroll-target="#useful-resources"><span class="header-section-number">3.15</span> Useful resources</a></li>
  <li><a href="#qa" id="toc-qa" class="nav-link" data-scroll-target="#qa"><span class="header-section-number">3.16</span> Q&amp;A</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-power" class="quarto-section-identifier"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Power</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Power is the probability that we reject the null hypothesis if it is false. It is a key component of experiment design because it determines the required sample size, which helps us determine how long we need to run an experiment for.</p>
<p>In this section, I want to do the following:</p>
<ul>
<li><p>Derive the formula for power from first principles.</p></li>
<li><p>Discuss implications of the formula for a number of experiment design aspects.</p></li>
<li><p>…</p></li>
</ul>
<section id="understanding-the-formula-that-determines-sample-size" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="understanding-the-formula-that-determines-sample-size"><span class="header-section-number">3.1</span> Understanding the formula that determines sample size</h2>
<p>first explain all the elements …</p>
<p>lh curve …this is sampling dist of tee, know shape from sampling theory reject h0 if value larger than za rhs is sampling distr under ha what is zk? now derive bloom formula…</p>
</section>
<section id="implications-of-the-formula" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="implications-of-the-formula"><span class="header-section-number">3.2</span> Implications of the formula</h2>
</section>
<section id="rules-of-thumb-the-big-16-vs-32-confusion" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="rules-of-thumb-the-big-16-vs-32-confusion"><span class="header-section-number">3.3</span> Rules of thumb – the big 16 vs 32 confusion</h2>
<ul>
<li><p>There is another way to express the variance, which has led to massive confusion.</p></li>
<li><p>I’m pretty sure its the 1/N vs 1/(N/2) error that accounts for the wrong result, and nobody seems to derive this from first principles to check.</p></li>
<li><p>Is original wrong? Check in book – access through WBS.</p></li>
</ul>
</section>
<section id="different-types-of-metrics" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="different-types-of-metrics"><span class="header-section-number">3.4</span> Different types of metrics</h2>
</section>
<section id="power-for-quasi-experimental-studies" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="power-for-quasi-experimental-studies"><span class="header-section-number">3.5</span> Power for quasi-experimental studies</h2>
</section>
<section id="deriving-the-sample-size-formula" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="deriving-the-sample-size-formula"><span class="header-section-number">3.6</span> Deriving the sample size formula</h2>
<p>The power formula can be intimidating and abstract (all the more so, because there are many different versions floating around).</p>
<p>The goal of this section is to demystify the formula. The best way to do that is to derive it from first principles, which will helps us understand where the formula comes from. In addition to the derivation from first principles, I’ll also show a couple other ways that are useful to understand it, and are a bit faster to use in practice.</p>
<section id="derivation-from-first-principles" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="derivation-from-first-principles"><span class="header-section-number">3.6.1</span> Derivation from first principles</h3>
<p>Power is the probability that we reject the null hypothesis if it is false:</p>
<p><span class="math display">\[
1 - \beta = P[\text{reject } H_0 | H_0 \text{ is false}].
\]</span></p>
<p>To derive the formula for power, we thus have to start with testing proceedure that determines whether or not we reject <span class="math inline">\(H_0\)</span>.</p>
<p>The null hypothesis asserts that there is no difference between treatment and control group, while the alternative hypothesis asserts that there is:</p>
<p><span class="math display">\[
\begin{align}
H_0: \te &amp;= \tef = 0 \\
H_A: \te &amp;= \tef \neq 0.
\end{align}
\]</span></p>
<p>We test the null hypothesis by constructing the test statistic</p>
<p><span class="math display">\[
Z = \frac{\tee}{\see}
\]</span></p>
<p>and reject the null hypothesis if</p>
<p><span class="math display">\[
|Z| &gt; z_{\alpha/2},
\]</span></p>
<p>where <span class="math inline">\(z_{\alpha/2}\)</span> is the critical value of the standard normal distribution at the <span class="math inline">\(\alpha/2\)</span> percentile. We thus reject <span class="math inline">\(H_0\)</span> if</p>
<p><span class="math display">\[
|\tee| &gt; \see z_{\alpha/2}
\]</span></p>
<p>The power of the test is the probability that the test statistic falls into the rejection region if <span class="math inline">\(H_A\)</span> is true, which is:</p>
<p><span class="math display">\[
1 - \beta = P\left[|\tee| &gt; \see z_{\alpha/2} | H_A \right].
\]</span></p>
<p>The test statistic falling into the lower or upper rejection region are mutually exclusive events, so the above is equal to</p>
<p><span class="math display">\[
1 - \beta = P\left[\tee &gt; \see z_{\alpha/2} | H_A \right]
+ P\left[\tee &lt; -\see z_{\alpha/2} | H_A \right].
\]</span></p>
<p>Standardising, using the assumption that <span class="math inline">\(H_A\)</span> is true, we get</p>
<p><span class="math display">\[
\begin{align}
1 - \beta &amp;= P\left[\frac{\tee - \te}{\see} &gt; \frac{\see z_{\alpha/2} - \te}{\see}\right]
+ P\left[\frac{\tee - \te}{\see} &lt; \frac{- \see z_{\alpha/2} - \te}{\see}\right] \\
&amp;= P\left[Z &gt; \frac{\see z_{\alpha/2} - \te}{\see}\right]
+ P\left[Z &lt; \frac{- \see z_{\alpha/2} - \te}{\see}\right],
\end{align}
\]</span></p>
<p>which, using the standard normal CDF, <span class="math inline">\(\Phi(z)\)</span>, we can rewrite as</p>
<p><span class="math display">\[
1 - \beta = \left[1 - \Phi\left(z_{\alpha/2} - \frac{\te}{\see}\right)\right]
+ \left[\Phi\left(-z_{\alpha/2} - \frac{\te}{\see}\right)\right].
\]</span></p>
<p>The probability that we reject the null hypothesis for the wrong reason – because the test statistic falls below the lower critical value for a true positive effect or above the upper critical value for a true negative effect – is very small.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Hence, as the true effect size deviates from zero, one of the two terms in the expression above becomes vanishingly small and can be ignored. For the rest of this chapter, I assume we have a true positive effect and omit the second of the two terms. We thus have:</p>
<p><span class="math display">\[
1 - \beta = 1 - \Phi\left(z_{\alpha/2} - \frac{\te}{\see}\right).
\]</span></p>
<p>Furthermore, using the symmetry of the standard normal distribution, which implies that <span class="math inline">\(1 - \Phi(k) = \Phi(-k)\)</span>, we can simplify this to</p>
<p><span class="math display">\[
1 - \beta = \Phi\left(\frac{\te}{\see} - z_{\alpha/2}\right).
\]</span></p>
<p>For a simple experiment with two variants with equal population variance, the estimated standard error of the treatment effect is given by (see <a href="experiment_stats.html" class="quarto-xref"><span>Chapter 7</span></a>)</p>
<p><span class="math display">\[
\see = \seefe = \seefep
\]</span></p>
<p>where <span class="math inline">\(\sev\)</span> is the pooled estimator of the population variance, <span class="math inline">\(\Nt\)</span> and <span class="math inline">\(\Nc\)</span> are the number of units in the treatment and control groups, respectively, <span class="math inline">\(\N = \Nt + \Nc\)</span> is total sample size, and <span class="math inline">\(P\)</span> is the proportion of units in the treatment group.</p>
<p>For such an experiment, the power is thus given by</p>
<p><span class="math display">\[
1 - \beta = \Phi\left(\frac{\te}{\seefep} - z_{\alpha/2}\right),
\]</span></p>
<p>which, with a bit of algebra (using <span class="math inline">\(1/\sqrt{1/x} = \sqrt{x}\)</span>), we can rewrite as</p>
<p><span id="eq-power"><span class="math display">\[
1 - \beta = \Phi\left(\frac{\te}{\sev}\sqrt{P(1-P)N} - z_{\alpha/2}\right).
\tag{3.1}\]</span></span></p>
<p>To calculate the required sample size for an experiment, we can rearrange <a href="#eq-power" class="quarto-xref">Equation&nbsp;<span>3.1</span></a> and solve for <span class="math inline">\(N\)</span>. To do this, we use the inverse of the CDS function <span class="math inline">\(\Phi(z)\)</span>. <span class="math inline">\(\Phi(z)\)</span> takes z-values and returns probabilities, so its inverse, <span class="math inline">\(\Phi(p)^{-1}\)</span>, takes probabilities and returns z-values. Using this, we get:</p>
<p><span class="math display">\[
\begin{align}
\Phi(1 - \beta)^{-1} &amp;= \Phi\left(\Phi\left(\frac{\te}{\sev}\sqrt{P(1-P)N} - z_{\alpha/2}\right)\right)^{-1} \\
z_{1 - \beta} &amp;= \frac{\te}{\sev}\sqrt{P(1-P)N} - z_{\alpha/2} \\
\sqrt{P(1-P)N} &amp;= (z_{1 - \beta} + z_{\alpha/2})\left(\frac{\sev}{\te}\right) \\
N &amp;= \frac{(z_{1 - \beta} + z_{\alpha/2})^2}{P(1-P)}\left(\frac{\sev}{\te}\right)^2.
\end{align}
\]</span></p>
</section>
<section id="starting-from-type-i-and-type-ii-error-conditions" class="level3" data-number="3.6.2">
<h3 data-number="3.6.2" class="anchored" data-anchor-id="starting-from-type-i-and-type-ii-error-conditions"><span class="header-section-number">3.6.2</span> Starting from Type I and Type II error conditions</h3>
</section>
<section id="starting-from-graphical-illustration" class="level3" data-number="3.6.3">
<h3 data-number="3.6.3" class="anchored" data-anchor-id="starting-from-graphical-illustration"><span class="header-section-number">3.6.3</span> Starting from graphical illustration</h3>
<p><span class="citation" data-cites="bloom1995minimum">Bloom (<a href="#ref-bloom1995minimum" role="doc-biblioref">1995</a>)</span> introduces the notion of the MDE as a useful way to quantify power. In the process, he also uses an intuitive way to derive the power formula based on an illustration of a typical hypothesis-testing scenario.</p>
<div id="fig-power" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-power-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../inputs/power.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-power-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3.1: Source: <span class="citation" data-cites="duflo2007using">Duflo, Glennerster, and Kremer (<a href="#ref-duflo2007using" role="doc-biblioref">2007</a>)</span>, based on <span class="citation" data-cites="bloom1995minimum">Bloom (<a href="#ref-bloom1995minimum" role="doc-biblioref">1995</a>)</span>.
</figcaption>
</figure>
</div>
<p>Let’s start by understanding <a href="#fig-power" class="quarto-xref">Figure&nbsp;<span>3.1</span></a>, which visualises the setup of a one-sided hypothesis test where the true effect equals 0 under the null hypothesis and some positive constant <span class="math inline">\(\te\)</span> under the alternative hypothesis. Note that the curves are <em>not</em> the standard normal distribution, but the sampling distribution of our estimator <span class="math inline">\(\tee\)</span>. This means that the standard deviation of the curves is given by the standard error of <span class="math inline">\(\tee\)</span>, which is <span class="math inline">\(\see\)</span>. Under the assumption of a homogenous treatment effect, the standard error is identical under <span class="math inline">\(\hn\)</span> and <span class="math inline">\(\ha\)</span>, which is why the two curves have the same shape (see <a href="experiment_stats.html" class="quarto-xref"><span>Chapter 7</span></a> for details).</p>
<p>the distribution will be the same under both the null and the alternative hypothesis, with the center of each distribution given by our hypothesised value of <span class="math inline">\(\te\)</span> – zero under <span class="math inline">\(\hn\)</span> and a positive constant under <span class="math inline">\(\ha\)</span>.</p>
<p>We reject <span class="math inline">\(\hn\)</span> if <span class="math inline">\(\tee\)</span> is to the right of the critical value <span class="math inline">\(\za\)</span>. Also, for a given level of power <span class="math inline">\(\beta\)</span>,</p>
</section>
</section>
<section id="old-notes" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="old-notes"><span class="header-section-number">3.7</span> Old notes</h2>
<!-- ## Theory -->
<!-- - Largely based on @duflo2007randomization -->
<p>Power basics</p>
<ul>
<li>In the simplest possible, we randomly draw a sample of size <span class="math inline">\(N\)</span> from an identical population, so that our observations can be assumed to be i.i.d, and we allocate a fraction <span class="math inline">\(P\)</span> of our sample to treatment. We can then estiamte the treatment effect using the OLS regression</li>
</ul>
<p><span class="math display">\[ y = \alpha + \beta T + \epsilon\]</span></p>
<ul>
<li><p>where the standard error of <span class="math inline">\(\beta\)</span> is given by <span class="math inline">\(\sqrt{\frac{1}{P(1-P)}\frac{\sigma^2}{N}}\)</span>.</p></li>
<li><p>std error derivation (from standard variance result of two independent samples, using population fractions):</p></li>
</ul>
<p><span class="math display">\[
std = \sqrt{\frac{\sigma^2}{N_t} + \frac{\sigma^2}{N_c}} = \sqrt{\frac{\sigma^2}{PN} + \frac{\sigma^2}{(1-P)N}} = ... = \sqrt{\frac{1}{P(1-P)}\frac{\sigma^2}{N}}
\]</span></p>
<ul>
<li><p>The distribution on the left hand side below shows the distribution of our effect size estimator <span class="math inline">\(\hat{\beta}\)</span> if the null hypothesis is true.</p></li>
<li><p>We reject the null hypothesis if the estimated effect size is larger than the critical value <span class="math inline">\(t_{\alpha}\)</span>, determined by the significance level <span class="math inline">\(\alpha\)</span>. Hence, for this to happen we need <span class="math inline">\(\hat{\beta} &gt; t_{\alpha} * SE(\hat{\beta})\)</span> (follows from rearranging the t-test formula).</p></li>
<li><p>On the right is the distribution of <span class="math inline">\(\hat{\beta}\)</span> if the true effect size is <span class="math inline">\(\beta\)</span>.</p></li>
<li><p>The power of the test for a true effect size of <span class="math inline">\(\beta\)</span> is the area under this curve that falls to the right of <span class="math inline">\(t_{\alpha}\)</span>. This is the probability that we reject the null hypothesis given that it is false.</p></li>
<li><p>Hence, to attain a power of <span class="math inline">\(\kappa\)</span> it must be that <span class="math inline">\(\beta &gt; (t_a + t_{1-\kappa}) * SE(\hat{\beta})\)</span>, where <span class="math inline">\(t_{1-\kappa}\)</span> is the value from a t-distribution that has <span class="math inline">\(1-\kappa\)</span> of its probability mass to the left (for <span class="math inline">\(\kappa = 0.8\)</span>, <span class="math inline">\(t_{1-\kappa} = 0.84\)</span>).</p></li>
<li><p>This means that the minimum detectable effect (<span class="math inline">\(\delta\)</span>) is given by:</p></li>
</ul>
<p><span class="math display">\[ \delta = (t_a + tq_{1-\kappa}) * \sqrt{\frac{1}{P(1-P)}\frac{\sigma^2}{N}} \]</span></p>
<ul>
<li>Rearranding for the minimum required sample size we get:</li>
</ul>
<p><span class="math display">\[ N =  \frac{(t_a + t_{1-\kappa})^2}{P(1-P)}\left(\frac{\sigma}{\delta}\right)^2 \]</span></p>
<ul>
<li><p>So that the required sample size is inversely proportional to the minimal effect size we wish to detect. This makes sense, it means that the smaller an effect we want to detect, the larger the samle size we need. In particular, given that <span class="math inline">\(N \propto \delta^{-2}\)</span>, to detect an effect of half the size we need a sample four times the size.</p></li>
<li><p>SE(<span class="math inline">\(\beta\)</span>) also includes measurement error, so this is also a determinant of power.</p></li>
</ul>
</section>
<section id="what-determines-power" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="what-determines-power"><span class="header-section-number">3.8</span> What determines power</h2>
<ul>
<li><p>Significance level</p></li>
<li><p>Effect size</p></li>
<li><p>Standard error</p>
<ul>
<li><p>Sample size</p></li>
<li><p>Variant allocation proportion</p></li>
<li><p>Metric variance</p></li>
</ul></li>
</ul>
</section>
<section id="how-to-increase-power" class="level2" data-number="3.9">
<h2 data-number="3.9" class="anchored" data-anchor-id="how-to-increase-power"><span class="header-section-number">3.9</span> How to increase power</h2>
<ul>
<li><p>Power can be increased trivially by lowering the significance level, which we often don’t want to do, or by increasing sample size, which we’re often trying to avoid.</p></li>
<li><p>Increase effect size</p>
<ul>
<li>Ensure that only users who are exposed to the change are in the data to avoid dilution of the effect</li>
</ul></li>
<li><p>Optimally allocate variance proportions</p>
<ul>
<li><p>Usually equal for highest power</p></li>
<li><p>Show why with many treatment variants, higher share in control is better</p></li>
</ul></li>
<li><p>Reduce metric variance</p>
<ul>
<li><p>Choose metric with low variance (e.g.&nbsp;indicator)</p></li>
<li><p>Use variance reduction technique</p></li>
<li><p>Only include triggered users</p></li>
</ul></li>
</ul>
</section>
<section id="how-to-choose-key-parameters" class="level2" data-number="3.10">
<h2 data-number="3.10" class="anchored" data-anchor-id="how-to-choose-key-parameters"><span class="header-section-number">3.10</span> How to choose key parameters</h2>
<section id="mde" class="level3" data-number="3.10.1">
<h3 data-number="3.10.1" class="anchored" data-anchor-id="mde"><span class="header-section-number">3.10.1</span> MDE</h3>
<ul>
<li><p>What are you balancing here? The size of the effect you are able to identify and the time it takes to do it.</p></li>
<li><p>All else equal, the smaller a change you want to be able to detect, the longer it will take for the experiment to run because you need more sample size.</p></li>
<li><p>The relevant question to ask here is “what counts as a practically relevant change?”</p></li>
<li><p>To answer that, consider:</p>
<ul>
<li><p>Maturity of service (the more mature, the smaller a change can be expected)</p></li>
<li><p>Size of service (the larger, the smaller a change still generates a lot of revenue)</p></li>
<li><p>Cost of change that need ot be covered</p>
<ul>
<li><p>Cost of fully building out feature for launch (can be 0 when fully built out for experiment or high if we use painted door)</p></li>
<li><p>Cost of maintaining new code (new code has higher bugs, may increase code complexity and maintenance)</p></li>
<li><p>Other costs: e.g.&nbsp;does CPU utilization increase?</p></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="significance-level" class="level3" data-number="3.10.2">
<h3 data-number="3.10.2" class="anchored" data-anchor-id="significance-level"><span class="header-section-number">3.10.2</span> Significance level</h3>
<ul>
<li><p>What are you balancing here? The probabilities of making a type I and type II error.</p></li>
<li><p>The higher significance level, the less likely we are to implement useless features (to make a Type I error) but the more likely we are to no implement useful features (to make a Type II error).</p></li>
<li><p>Hence, gotta balance cost of implementing useless feature and cost of not implementing useful feature.</p></li>
<li><p>Things that play into this:</p>
<ul>
<li><p>How long will feature be in effect (less long lowers risk of implementing)?</p></li>
<li><p>How widely will it be deployed (less widely lowers risk of implementing)?</p></li>
<li><p>How many users will see it / where in the funnel is it (later in funnel lowers risk of implementation)</p></li>
</ul></li>
<li><p>What to do in practice:</p>
<ul>
<li><p>Start from baseline values (<span class="math inline">\(alpha = 0.05\)</span>)</p></li>
<li><p>Adjust depending on balance of risks</p></li>
</ul></li>
</ul>
</section>
<section id="power" class="level3" data-number="3.10.3">
<h3 data-number="3.10.3" class="anchored" data-anchor-id="power"><span class="header-section-number">3.10.3</span> Power</h3>
<ul>
<li><p>What are you balancing here? The risk of making a Type II error and the time you have to wait for your results.</p></li>
<li><p>All else equal, the higher a level or power you want, the longer you’ll have to run the experiment to accumulate the requried sample size.</p></li>
<li><p>Factors to consider:</p>
<ul>
<li>How costly is it to not implement a useful feature.</li>
</ul></li>
</ul>
</section>
</section>
<section id="problems-with-low-power" class="level2" data-number="3.11">
<h2 data-number="3.11" class="anchored" data-anchor-id="problems-with-low-power"><span class="header-section-number">3.11</span> Problems with low power</h2>
<ul>
<li>Truth inflation: underpowered studies only find a significant effect it the effect size is larger than the true effect size, leading to inflated claims of effect sizes.</li>
</ul>
</section>
<section id="power-in-online-experiments" class="level2" data-number="3.12">
<h2 data-number="3.12" class="anchored" data-anchor-id="power-in-online-experiments"><span class="header-section-number">3.12</span> Power in online experiments</h2>
<ul>
<li><span class="citation" data-cites="kohavi2014seven">Kohavi et al. (<a href="#ref-kohavi2014seven" role="doc-biblioref">2014</a>)</span> point out (in rule 7) that while general advice suggets that the CLT provides a good approximation for n larger than 30, the large skew in online metrics often requires many moer users. They recomment 355 * (skewness coefficient)^2.</li>
</ul>
</section>
<section id="rule-of-thumb-for-sample-size" class="level2" data-number="3.13">
<h2 data-number="3.13" class="anchored" data-anchor-id="rule-of-thumb-for-sample-size"><span class="header-section-number">3.13</span> Rule of thumb for sample size</h2>
<p>For alpha = 0.05, power = 0.8, and a two-sided test with equal allocation to two variants, required sample size per variant is approximately:</p>
<p><span class="math display">\[
n \approx \frac{16\sigma^2}{\tau^2},
\]</span></p>
<p>where <span class="math inline">\(\sigma^2\)</span> is the sample variance and <span class="math inline">\(\tau\)</span> is the tretment effect (this is not known, but we can use the MDES).</p>
<p>The formula straighforwardly comes from <a href="#eq-power" class="quarto-xref">Equation&nbsp;<span>3.1</span></a>, using 1.96 for <span class="math inline">\(t_\alpha\)</span>, 0.84 for <span class="math inline">\(t_{1 - \beta}\)</span>, and 0.5 for <span class="math inline">\(P\)</span>.</p>
</section>
<section id="best-practices" class="level2" data-number="3.14">
<h2 data-number="3.14" class="anchored" data-anchor-id="best-practices"><span class="header-section-number">3.14</span> Best practices</h2>
<ul>
<li>When aiming to estimate a precise effect size rather than just being interested in statistical significance, use assurance instead of power: instead of choosing a sample size to attain a given level of power, choose sample size so that confidence interval will be suitably narrow 99 percent of the time (<a href="https://www3.nd.edu/~kkelley/publications/articles/Anderson_Kelley_Maxwell_Psychological_Science_2017.pdf">Sample-Size Planning for More Accurate Statistical Power: A Method Adjusting Sample Effect Sizes for Publication Bias and Uncertainty</a> and <a href="https://tandfbis.s3.amazonaws.com/rt-media/pp/common/sample-chapters/9780415879682.pdf">Understanding the new statistics</a>.)</li>
</ul>
</section>
<section id="useful-resources" class="level2" data-number="3.15">
<h2 data-number="3.15" class="anchored" data-anchor-id="useful-resources"><span class="header-section-number">3.15</span> Useful resources</h2>
<ul>
<li><span class="citation" data-cites="larsen2023statistical">Larsen et al. (<a href="#ref-larsen2023statistical" role="doc-biblioref">2023</a>)</span> for general overview</li>
<li><span class="citation" data-cites="zhou2023all">Zhou, Lu, and Shallah (<a href="#ref-zhou2023all" role="doc-biblioref">2023</a>)</span> for comprehensive overview of how to calculate power</li>
<li><span class="citation" data-cites="bojinov2023design">Bojinov, Simchi-Levi, and Zhao (<a href="#ref-bojinov2023design" role="doc-biblioref">2023</a>)</span>, section 5, for simulation results for switchbacks and generally good approach to simulation to emulate</li>
<li><span class="citation" data-cites="reich2012empirical">Reich et al. (<a href="#ref-reich2012empirical" role="doc-biblioref">2012</a>)</span> power calcs for cluster-randomised experiments</li>
</ul>
</section>
<section id="qa" class="level2" data-number="3.16">
<h2 data-number="3.16" class="anchored" data-anchor-id="qa"><span class="header-section-number">3.16</span> Q&amp;A</h2>
<p>Questions:</p>
<ol type="1">
<li><p>Longer experiment duration generally increases power. Can you think of a scenario where this is not the case?</p></li>
<li><p>An online shopping site ranks products according to their average rating. Why might this be suboptimal? What could the site do instead?</p></li>
</ol>
<p>Answers:</p>
<ol type="1">
<li><p>When using a cumulative metric such as number of likes, the variance of which will increase the longer the experiment runs, which will increase the standard error of our treatment effect estimate and lower our power. Remember that <span class="math inline">\(SE(\hat{\tau}) = \sqrt{\frac{1}{P(1-P)}\frac{\sigma^2}{N}}\)</span>. So, whether this happens depends on what happens to <span class="math inline">\(\frac{\sigma^2}{N}\)</span>, as experiment duration increases. A decrease in power is plausible – likely, even! – because <span class="math inline">\(N\)</span> will increase in a concave fashion over the course of the experiment duration (some users keep coming back), while <span class="math inline">\(\sigma^2\)</span> is likely to grow faster than linearly, which causes the ratio to increase and power to decrease.</p></li>
<li><p>The approach is suboptimal because products with few ratings will have much more variance than products with many ratings, and their average rating is thus less reliable. The problem is akin to small US states having the highest <em>and</em> lowest rates of kidney cancer, or small schools having highest <em>and</em> lowest average pupil performance. Fundamentally, it’s a problem of low power – the sample size is too low to reliably detect a true effect. The solution is to use a shrinkage method: use a weighted average of the product average rating and some global product rating, with the weight of the product average rating being proportional to the number of ratings. This way, products with few ratings will be average, while products with many ratings will reflect their own rating.</p></li>
</ol>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-bloom1995minimum" class="csl-entry" role="listitem">
Bloom, Howard S. 1995. <span>“Minimum Detectable Effects: A Simple Way to Report the Statistical Power of Experimental Designs.”</span> <em>Evaluation Review</em> 19 (5): 547–56.
</div>
<div id="ref-bojinov2023design" class="csl-entry" role="listitem">
Bojinov, Iavor, David Simchi-Levi, and Jinglong Zhao. 2023. <span>“Design and Analysis of Switchback Experiments.”</span> <em>Management Science</em> 69 (7): 3759–77.
</div>
<div id="ref-duflo2007using" class="csl-entry" role="listitem">
Duflo, Esther, Rachel Glennerster, and Michael Kremer. 2007. <span>“Using Randomization in Development Economics Research: A Toolkit.”</span> <em>Handbook of Development Economics</em> 4: 3895–3962.
</div>
<div id="ref-kohavi2014seven" class="csl-entry" role="listitem">
Kohavi, Ron, Alex Deng, Roger Longbotham, and Ya Xu. 2014. <span>“Seven Rules of Thumb for Web Site Experimenters.”</span> In <em>Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>, 1857–66.
</div>
<div id="ref-larsen2023statistical" class="csl-entry" role="listitem">
Larsen, Nicholas, Jonathan Stallrich, Srijan Sengupta, Alex Deng, Ron Kohavi, and Nathaniel T Stevens. 2023. <span>“Statistical Challenges in Online Controlled Experiments: A Review of a/b Testing Methodology.”</span> <em>The American Statistician</em>, 1–15.
</div>
<div id="ref-reich2012empirical" class="csl-entry" role="listitem">
Reich, Nicholas G, Jessica A Myers, Daniel Obeng, Aaron M Milstone, and Trish M Perl. 2012. <span>“Empirical Power and Sample Size Calculations for Cluster-Randomized and Cluster-Randomized Crossover Studies.”</span> <em>PloS One</em> 7 (4): e35564.
</div>
<div id="ref-zhou2023all" class="csl-entry" role="listitem">
Zhou, Jing, Jiannan Lu, and Anas Shallah. 2023. <span>“All about Sample-Size Calculations for a/b Testing: Novel Extensions and Practical Guide.”</span> <em>arXiv Preprint arXiv:2305.16459</em>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>This kind of error is somtimes called a <a href="https://en.wikipedia.org/wiki/Type_III_error">Type III error</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/stats_foundations.html" class="pagination-link  aria-label=" &lt;span="" foundation&lt;="" span&gt;"="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Statistics foundation</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/projection.html" class="pagination-link" aria-label="<span class='chapter-number'>4</span>&nbsp; <span class='chapter-title'>Projection</span>">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Projection</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>