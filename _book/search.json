[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Causal inference notes",
    "section": "",
    "text": "In this space I want to collect my notes on causal inference.\nIf you find them helpful, find any errors, or have any suggestions, please get in touch by writing to fa.gunzinger@gmail.com."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Collaboration (2015) for additional discussion of literate programming.\n\n\n\n\nCollaboration, Open Science. 2015. “Estimating the Reproducibility of Psychological Science.” Science 349 (6251): aac4716."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Collaboration, Open Science. 2015. “Estimating the Reproducibility\nof Psychological Science.” Science 349 (6251): aac4716."
  },
  {
    "objectID": "fundamentals.html",
    "href": "fundamentals.html",
    "title": "Fundamentals",
    "section": "",
    "text": "Some fundamentals here"
  },
  {
    "objectID": "philosophy.html",
    "href": "philosophy.html",
    "title": "Fundamentals",
    "section": "",
    "text": "Some fundamentals here"
  },
  {
    "objectID": "practice.html",
    "href": "practice.html",
    "title": "Practice",
    "section": "",
    "text": "This part covers issues that arise in practice when we attempt to estimate causal effects."
  },
  {
    "objectID": "ci_introduction.html#fundamental-problem-of-causal-inference",
    "href": "ci_introduction.html#fundamental-problem-of-causal-inference",
    "title": "4  Introduction",
    "section": "4.1 Fundamental problem of causal inference",
    "text": "4.1 Fundamental problem of causal inference"
  },
  {
    "objectID": "ci_introduction.html#sources-of-bias",
    "href": "ci_introduction.html#sources-of-bias",
    "title": "4  Introduction",
    "section": "4.2 Sources of bias",
    "text": "4.2 Sources of bias\nFrom King and Zeng (2006), section 3.2 onwards 1. Omitted variable bias 2. Posttreatment bias (including variables in X that are result of T) 3. Interpolation bias () 4. Extrapolation bias\n\n\n\n\nKing, Gary, and Langche Zeng. 2006. “The Dangers of Extreme Counterfactuals.” Political Analysis 14 (2): 131–59."
  },
  {
    "objectID": "fundamental_problem.html#sources-of-bias",
    "href": "fundamental_problem.html#sources-of-bias",
    "title": "4  Fundamental problem of causal inference",
    "section": "4.1 Sources of bias",
    "text": "4.1 Sources of bias\nFrom King and Zeng (2006), section 3.2 onwards 1. Omitted variable bias 2. Posttreatment bias (including variables in X that are result of T) 3. Interpolation bias () 4. Extrapolation bias\n\n\n\n\nKing, Gary, and Langche Zeng. 2006. “The Dangers of Extreme Counterfactuals.” Political Analysis 14 (2): 131–59."
  },
  {
    "objectID": "dags.html",
    "href": "dags.html",
    "title": "6  Directed Acyclic Graphs",
    "section": "",
    "text": "A confounder is a variable that simultaneously affects the treatment indicator and the outcome (the same as an omitted variable).\nA collider is a variable that is simultaneously affected by the treatment indicator and the outcome.\nA backdoor path is a path from the treatment indicator to the outcome via a confounder.\nThere are two ways to close a backdoor path:\n\nControl for the confounder if it is available\nHave a collider on the backdoor path\n\nAn analysis design meets the backdoor criterion if all backdoor paths are closed, in which case we have isolated a causal effect."
  },
  {
    "objectID": "regression_discontinuity.html#use-cases",
    "href": "regression_discontinuity.html#use-cases",
    "title": "10  Regression discontinuity design",
    "section": "10.1 Use cases",
    "text": "10.1 Use cases\n\nIdentifiable forcing variable"
  },
  {
    "objectID": "regression_discontinuity.html#considerations",
    "href": "regression_discontinuity.html#considerations",
    "title": "10  Regression discontinuity design",
    "section": "10.2 Considerations",
    "text": "10.2 Considerations\n\nFunctional form: use local linear methods\nChoice of bandwidth: use asymptotic expansion\nAssessing (internal) validity: use suplementary analysis\nAssessing external validity: assess credibility of extrapolation to other subpopulations\n\nNotes based on Athey and Imbens (2017)\n\n\n\n\nAthey, Susan, and Guido W Imbens. 2017. “The State of Applied Econometrics: Causality and Policy Evaluation.” Journal of Economic Perspectives 31 (2): 3–32."
  },
  {
    "objectID": "useful_resources.html",
    "href": "useful_resources.html",
    "title": "12  Useful resources",
    "section": "",
    "text": "Getting to decisions faster in A/B tests – useful literature review of various moderl approaches to A/B testing"
  },
  {
    "objectID": "matching.html",
    "href": "matching.html",
    "title": "9  Matching",
    "section": "",
    "text": "ad"
  },
  {
    "objectID": "practical_issues.html",
    "href": "practical_issues.html",
    "title": "8  Practical issues",
    "section": "",
    "text": "For useful set of rules of thumb, see Kohavi papers as well as this CUPED post\nFor great outline of experiment platform and used methods see this Uber post.\n\nNotes from larsen2023statistical\n\nReasons for insufficient power\n\nTreatment effect is homogenously distributed across entire user base but very small\nFeature affects only small number of users, so overall effect is highly attenuated\nTreatment effect on known subgroups is of interest"
  },
  {
    "objectID": "chapters/intro.html",
    "href": "chapters/intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Collaboration (2015) for additional discussion of literate programming.\n\n\n\n\nCollaboration, Open Science. 2015. “Estimating the Reproducibility of Psychological Science.” Science 349 (6251): aac4716."
  },
  {
    "objectID": "chapters/fundamental_problem.html#sources-of-bias",
    "href": "chapters/fundamental_problem.html#sources-of-bias",
    "title": "4  Fundamental problem of causal inference",
    "section": "4.1 Sources of bias",
    "text": "4.1 Sources of bias\nFrom King and Zeng (2006), section 3.2 onwards 1. Omitted variable bias 2. Posttreatment bias (including variables in X that are result of T) 3. Interpolation bias () 4. Extrapolation bias\n\n\n\n\nKing, Gary, and Langche Zeng. 2006. “The Dangers of Extreme Counterfactuals.” Political Analysis 14 (2): 131–59."
  },
  {
    "objectID": "chapters/dags.html",
    "href": "chapters/dags.html",
    "title": "6  Directed Acyclic Graphs",
    "section": "",
    "text": "A confounder is a variable that simultaneously affects the treatment indicator and the outcome (the same as an omitted variable).\nA collider is a variable that is simultaneously affected by the treatment indicator and the outcome.\nA backdoor path is a path from the treatment indicator to the outcome via a confounder.\nThere are two ways to close a backdoor path:\n\nControl for the confounder if it is available\nHave a collider on the backdoor path\n\nAn analysis design meets the backdoor criterion if all backdoor paths are closed, in which case we have isolated a causal effect."
  },
  {
    "objectID": "chapters/practical_issues.html",
    "href": "chapters/practical_issues.html",
    "title": "11  Practical issues",
    "section": "",
    "text": "For useful set of rules of thumb, see Kohavi papers as well as this CUPED post\nFor great outline of experiment platform and used methods see this Uber post.\n\nNotes from larsen2023statistical\n\nReasons for insufficient power\n\nTreatment effect is homogenously distributed across entire user base but very small\nFeature affects only small number of users, so overall effect is highly attenuated\nTreatment effect on known subgroups is of interest"
  },
  {
    "objectID": "chapters/regression_discontinuity.html#use-cases",
    "href": "chapters/regression_discontinuity.html#use-cases",
    "title": "13  Regression discontinuity design",
    "section": "13.1 Use cases",
    "text": "13.1 Use cases\n\nIdentifiable forcing variable"
  },
  {
    "objectID": "chapters/regression_discontinuity.html#considerations",
    "href": "chapters/regression_discontinuity.html#considerations",
    "title": "13  Regression discontinuity design",
    "section": "13.2 Considerations",
    "text": "13.2 Considerations\n\nFunctional form: use local linear methods\nChoice of bandwidth: use asymptotic expansion\nAssessing (internal) validity: use suplementary analysis\nAssessing external validity: assess credibility of extrapolation to other subpopulations\n\nNotes based on Athey and Imbens (2017)\n\n\n\n\nAthey, Susan, and Guido W Imbens. 2017. “The State of Applied Econometrics: Causality and Policy Evaluation.” Journal of Economic Perspectives 31 (2): 3–32."
  },
  {
    "objectID": "chapters/references.html",
    "href": "chapters/references.html",
    "title": "References",
    "section": "",
    "text": "Imbens, Guido W, and Donald B Rubin. 2015. Causal Inference in\nStatistics, Social, and Biomedical Sciences. Cambridge University\nPress.\n\n\nKarrer, Brian, Liang Shi, Monica Bhole, Matt Goldman, Tyrone Palmer,\nCharlie Gelman, Mikael Konutgan, and Feng Sun. 2021. “Network\nExperimentation at Scale.” In Proceedings of the 27th Acm\nSigkdd Conference on Knowledge Discovery & Data Mining,\n3106–16."
  },
  {
    "objectID": "chapters/useful_resources.html",
    "href": "chapters/useful_resources.html",
    "title": "11  Useful resources",
    "section": "",
    "text": "Getting to decisions faster in A/B tests – useful literature review of various moderl approaches to A/B testing"
  },
  {
    "objectID": "chapters/projection.html",
    "href": "chapters/projection.html",
    "title": "8  Projection",
    "section": "",
    "text": "A projection is a transformation of a vector onto a subspace. There are different types of projections, but the one that’s relevant for us here is orthogonal projection.\n\\[\n\\begin{aligned}\n\\alpha &= \\beta \\\\\n&= \\delta\n\\end{aligned}\n\\]\npython -m pip install rosalie\n\nimport pandas as pd\ndf = pd.DataFrame({'a': [1, 2, 3]})\ndf.head()\n\n\n\n\n\n\n\n\na\n\n\n\n\n0\n1\n\n\n1\n2\n\n\n2\n3"
  },
  {
    "objectID": "chapters/projection.html#projection-in-1-d",
    "href": "chapters/projection.html#projection-in-1-d",
    "title": "8  Projection",
    "section": "8.1 Projection in 1-D",
    "text": "8.1 Projection in 1-D\nProjecting a vector in two-dimensional space onto a line through the origin is a nice way to build an understanding for what a projection does.2"
  },
  {
    "objectID": "chapters/projection.html#references",
    "href": "chapters/projection.html#references",
    "title": "8  Projection",
    "section": "8.5 References",
    "text": "8.5 References\n\nGilbert Strang’s linear algebra lectures at MIT\n10 Fundamental Theorems for Econometrics"
  },
  {
    "objectID": "chapters/projection.html#footnotes",
    "href": "chapters/projection.html#footnotes",
    "title": "2  Projection",
    "section": "",
    "text": "A subspace is a subset of a vector space that is itself a vector space in which any possible linear combination of two vectors in the space is also in the space. For instance, a 2-dimensional plane is a subspace of \\(\\mathbb{R}^3\\) if it contains all possible linear combinations of any 2-dimensional vectors. For this to be the case, the plane has to go through the origin – the point (0, 0, 0) – to contain linear combinations with the zero scalar. Similarly, a line that goes through the origin is also a valid subspace, since any linear combination of two vectors that lie on the line will also lie on the line.↩︎\nThe Euclidean distance between two points \\(x\\) and \\(\\bar{x}\\) in \\(\\mathbb{R}^N\\) is defined as \\(\\sqrt{\\sum_{i=1}^N{(\\bar{x_i} - x_i})^2}\\).↩︎\nA line through the origin is a subspace of a two-dimensional vector because it is 1-dimensional (and thus a subset of the 2-dimensional vector) and because all possible linear combinations of vectors on the line will also lie on the line (the line needs to pass through the origin for this latter statement to be true, see the footnote on subspaces).↩︎\nTODO explain concept of orthogonality and why it is equivalent to the dot-product being zero.↩︎\nTODO show what happens if we define \\(p = xa\\) instead of \\(p = ax\\)↩︎"
  },
  {
    "objectID": "chapters/projection.html#projection-onto-1-d",
    "href": "chapters/projection.html#projection-onto-1-d",
    "title": "8  Projection",
    "section": "8.1 Projection onto 1-D",
    "text": "8.1 Projection onto 1-D\nProjecting a vector in two-dimensional space onto a line that goes through the origin is a nice way to build an understanding for what a projection does.3\nSay we want to orthogonally project the vector \\(b\\) onto a line defined by another vector, \\(a\\), and we will call the resulting projection \\(p\\). Hence, \\(p\\) is the point on the line defined by \\(a\\) that is nearest to the (tip of) the vector \\(b\\).\nWe can think of the line as being generated by scaling vector \\(a\\) with a scalar \\(x\\), so that choosing a suitable \\(x\\) allows us to reach any point on the line. Finding \\(p\\) then boils down to finding the value of \\(x\\) that gets us to that point of the line that is closest to \\(b\\). We can thus write \\(p = ax\\).\n[todo: insert figure here]\nLet’s start by finding \\(p\\). We can find it in different ways.\nUsing calculus:\nMinimising the distance between the (tip of) the vector, \\(b\\), and the projection, \\(p\\), is akin to solving the following problem:\n\\[\n\\begin{aligned}\nargmin_{x} \\sqrt{\\sum_{i=1}^2{(b_i - p_i)^2}} &= argmin_{x} \\sum_{i=1}^2{(b_i - p_i)^2} \\\\\n&= argmin_{x} \\sum_{i=1}^2{(b_i - xa_i)^2} \\\\\n&= argmin_{x} (b - xa)'(b - xa),\n\\end{aligned}\n\\]\nCalculating the derivative with respect to \\(x\\) to zero we get:\n\\[\n\\begin{aligned}\n\\frac{d}{dx} (b - xa)'(b - xa) &= (-a)'(b - xa) + (b - xa)'(-a) & \\\\\n&= -a'b + xa'a - a'b + xa'a \\\\\n&= -2a'b + 2xa'a = 0\n\\end{aligned}\n\\]\nSolving for \\(x\\) we get:\n\\[\n\\begin{aligned}\n-2a'b + 2xa'a &= 0 \\\\\nxa'a &= a'b \\\\\nx &= (a'a)^{-1}a'b\n\\end{aligned}\n\\]\nHence, given that \\(p = ax\\), we have:\n\\[\n\\begin{aligned}\np = ax = \\underbrace{a(a'a)^{-1}a'}_\\text{$P_a$}b,\n\\end{aligned}\n\\]\nwhere \\(P_a\\) is the projection matrix.\nLet’s reflect for a moment what this all means. In general, pre-multiplying a vector by a matrix transforms the vector in a particular way. When we perform orthogonal projection, we pre-multiply a vector by a matrix that transforms the vector into that point on a subspace that it closest to the original vector. In our case here, pre-multiplying our initial vector \\(b\\) by the projection matrix \\(P_a\\) transforms \\(b\\) into that point on \\(a\\) that is closest to \\(b\\), which we call \\(p\\). Given that we define “nearest” using the Euclidean distance, it makes sense that the projection matrix would emerge out of the solution to the minimisation problem of finding the point on the subspace that minimises the Euclidean distance to the original vector.\nUsing basic geometry:\nWe could also find \\(p\\) using our understanding of basic geometry. Looking at the figure above, it is intuitively obvious that the shortest path between the tip of \\(b\\) and the projection \\(p\\) onto \\(a\\) is that which is perpendicular to the line \\(a\\). The path between \\(b\\) and \\(p\\) is simply \\(b - p\\). In linear algebra terms, we thus want that path to be orthogonal to the line \\(a\\).4\nHence, we want:\n\\[\n\\begin{aligned}\na'(b - p) &= 0 \\\\\na'(b - xa) &= 0 \\\\\na'b - xa'a &= 0 \\\\\nxa'a &= a'b \\\\\nx &= (a'a)^{-1}a'b\n\\end{aligned}\n\\]\nSo that, again, we have:5\n\\[\np = ax = \\underbrace{a(a'a)^{-1}a'}_\\text{$P_a$}b,\n\\]"
  },
  {
    "objectID": "chapters/projection.html#projection-onto-2-d-and-n-d.",
    "href": "chapters/projection.html#projection-onto-2-d-and-n-d.",
    "title": "8  Projection",
    "section": "8.3 Projection onto 2-D and N-D.",
    "text": "8.3 Projection onto 2-D and N-D."
  },
  {
    "objectID": "chapters/projection.html#useful-resources",
    "href": "chapters/projection.html#useful-resources",
    "title": "8  Projection",
    "section": "8.3 Useful resources",
    "text": "8.3 Useful resources"
  },
  {
    "objectID": "chapters/projection.html#why-project",
    "href": "chapters/projection.html#why-project",
    "title": "2  Projection",
    "section": "2.2 Why project?",
    "text": "2.2 Why project?\nProjection is useful because it allows us to approximately solve systems of linear equations that have no exact solution. Imagine we have the following system of equations:\n\\[\n\\begin{align*}\na_{11}x_1 + a_{12}x_2 + \\cdots + a_{1k}x_k &= b_1 \\\\\na_{21}x_1 + a_{22}x_2 + \\cdots + a_{2k}x_k &= b_2 \\\\\n\\vdots \\\\\na_{n1}x_1 + a_{n2}x_2 + \\cdots + a_{nk}x_k &= b_n\n\\end{align*}\n\\]\nwhich we can write more compactly in matrix form as:\n\\[\nAx = b.\n\\]\nIf \\(n &gt; k\\), the system is overdetermined – it has more constarints (equations) than degrees of freedom (variables) – and might not have a solution. In this case, it can be useful to solve\n\\[\nAx = \\hat{b},\n\\]\nwhere \\(\\hat{b}\\) is the orthogonal projection of \\(b\\) onto the vector space spanned by \\(A\\), called the span or column space of \\(A\\). Using orthogonal projection in this case achieves two things: it guarantees a solution because \\(\\hat{b}\\) lies on the same space as \\(Ax\\) – they both lie on the subspace spanned by the columns of \\(A\\) – and is makes \\(\\hat{p}\\) the best approximation to \\(b\\) in that it is closest to it in terms of the Euclidean distance."
  },
  {
    "objectID": "chapters/projection.html#projecting-from-2-d-onto-1-d",
    "href": "chapters/projection.html#projecting-from-2-d-onto-1-d",
    "title": "2  Projection",
    "section": "2.1 Projecting from 2-D onto 1-D",
    "text": "2.1 Projecting from 2-D onto 1-D\nProjecting a vector in two-dimensional space onto a line that goes through the origin is a nice way to build an understanding for what a projection does.3\nSay we want to orthogonally project the vector \\(b\\) onto a line defined by another vector, \\(a\\), and we will call the resulting projection \\(p\\). Hence, \\(p\\) is the point on the line defined by \\(a\\) that is nearest to the (tip of) the vector \\(b\\).\nWe can think of the line as being generated by scaling vector \\(a\\) with a scalar \\(x\\), so that choosing a suitable \\(x\\) allows us to reach any point on the line. Finding \\(p\\) then boils down to finding the value of \\(x\\) that gets us to that point of the line that is closest to \\(b\\). We can thus write \\(p = ax\\).\n[todo: insert figure here]\nLet’s start by finding \\(p\\). We can find it in different ways.\nUsing calculus:\nMinimising the distance between the (tip of) the vector, \\(b\\), and the projection, \\(p\\), is akin to solving the following problem:\n\\[\n\\begin{aligned}\nargmin_{x} \\sqrt{\\sum_{i=1}^2{(b_i - p_i)^2}} &= argmin_{x} \\sum_{i=1}^2{(b_i - p_i)^2} \\\\\n&= argmin_{x} \\sum_{i=1}^2{(b_i - xa_i)^2} \\\\\n&= argmin_{x} (b - xa)'(b - xa),\n\\end{aligned}\n\\]\nCalculating the derivative with respect to \\(x\\) to zero we get:\n\\[\n\\begin{aligned}\n\\frac{d}{dx} (b - xa)'(b - xa) &= (-a)'(b - xa) + (b - xa)'(-a) & \\\\\n&= -a'b + xa'a - a'b + xa'a \\\\\n&= -2a'b + 2xa'a = 0\n\\end{aligned}\n\\]\nSolving for \\(x\\) we get:\n\\[\n\\begin{aligned}\n-2a'b + 2xa'a &= 0 \\\\\nxa'a &= a'b \\\\\nx &= (a'a)^{-1}a'b\n\\end{aligned}\n\\]\nHence, given that \\(p = ax\\), we have:\n\\[\n\\begin{aligned}\np = ax = \\underbrace{a(a'a)^{-1}a'}_\\text{$P_a$}b,\n\\end{aligned}\n\\]\nwhere \\(P_a\\) is the projection matrix.\nLet’s reflect for a moment what this all means. In general, pre-multiplying a vector by a matrix transforms the vector in a particular way. When we perform orthogonal projection, we pre-multiply a vector by a matrix that transforms the vector into that point on a subspace that it closest to the original vector. In our case here, pre-multiplying our initial vector \\(b\\) by the projection matrix \\(P_a\\) transforms \\(b\\) into that point on \\(a\\) that is closest to \\(b\\), which we call \\(p\\). Given that we define “nearest” using the Euclidean distance, it makes sense that the projection matrix would emerge out of the solution to the minimisation problem of finding the point on the subspace that minimises the Euclidean distance to the original vector.\nUsing basic geometry:\nWe could also find \\(p\\) using our understanding of basic geometry. Looking at the figure above, it is intuitively obvious that the shortest path between the tip of \\(b\\) and the projection \\(p\\) onto \\(a\\) is that which is perpendicular to the line \\(a\\). The path between \\(b\\) and \\(p\\) is simply \\(b - p\\). In linear algebra terms, we thus want that path to be orthogonal to the line \\(a\\).4\nHence, we want:\n\\[\n\\begin{aligned}\na'(b - p) &= 0 \\\\\na'(b - xa) &= 0 \\\\\na'b - xa'a &= 0 \\\\\nxa'a &= a'b \\\\\nx &= (a'a)^{-1}a'b\n\\end{aligned}\n\\]\nSo that, again, we have:5\n\\[\np = ax = \\underbrace{a(a'a)^{-1}a'}_\\text{$P_a$}b.\n\\]\nThis also makes clear why this type of projection is called “orthogonal projection”: we want to project a vector onto a subspace in such a way that the distance between the original vector and the subspace is minimal. The resulting projection will be a point on the suspace such that a vector from that point to the original vector is orthogonal to the subspace. Intuitively, this is the case because the shortest path between the vector and the subspace will be that which is perpendicular to the subspace, and orthogonality is the generalisation of the notion of perpendicularity."
  },
  {
    "objectID": "chapters/projection.html#projection-from-3-d-onto-2-d",
    "href": "chapters/projection.html#projection-from-3-d-onto-2-d",
    "title": "8  Projection",
    "section": "8.3 Projection from 3-D onto 2-D",
    "text": "8.3 Projection from 3-D onto 2-D\nOur starting point is similar to the 2-D onto 1-D example above, but our vector \\(b\\) is now 3-dimensional and the subspace we project it onto is now not a 1-dimensional line but a 2-dimensional plane. Hence, \\(p\\) is now a point in the 3-dimensional space that lies on the 2-dimensional subspace. Above, we defined \\(p\\) as \\(p = ax\\), where \\(a\\) was the scalar that characterised the line and \\(x\\) the scalar that helped us move along that line. Similarly, we now have \\(p = Ax\\), where \\(A\\) is a 2 x 2 matrix, the two columns of which are the base vectors of the 2-dimensional subspace.\nWe can still go about finding \\(p\\) in the same way as above:\n\\[\n\\begin{aligned}\nargmin_{x} (b - Ax)'(b - Ax) \\\\\n\\frac{d}{dx} (b - Ax)'(b - Ax) &= -2A'(b - Ax) = 0\n\\end{aligned}\n\\]\nSolving for \\(x\\) we get: \\[\n\\begin{aligned}\n-2A'(b - Ax) &= 0 \\\\\n-A'b + A'Ax &= 0 \\\\\nA'Ax &= A'b \\\\\nx &= (A'A)^{-1}A'b\n\\end{aligned}\n\\]\nThe last step above works only if \\(A'A\\) is actually invertible, which is the case if \\(A\\) has full rank, which is the case if none of its columns can be constructed from a linear combination of any other columns. (A visual way to think about this is the following: the columns of a matrix are the basis vectors of its column space. The rank is the number of dimensions of that column space. Full rank means that the column space has as many dimensions as there are columns.)"
  },
  {
    "objectID": "chapters/projection.html#projection-from-3-d-onto-2-d-and-projecting-onto-n-d",
    "href": "chapters/projection.html#projection-from-3-d-onto-2-d-and-projecting-onto-n-d",
    "title": "2  Projection",
    "section": "2.3 Projection from 3-D onto 2-D and projecting onto N-D",
    "text": "2.3 Projection from 3-D onto 2-D and projecting onto N-D\nOur starting point is similar to the 2-D onto 1-D example above, but our vector \\(b\\) is now 3-dimensional and the subspace we project it onto is now not a 1-dimensional line but a 2-dimensional plane. Hence, \\(p\\) is now a point in the 3-dimensional space that lies on the 2-dimensional subspace. Above, we defined \\(p\\) as \\(p = ax\\), where \\(a\\) was the scalar that characterised the line and \\(x\\) the scalar that helped us move along that line. Similarly, we now have \\(p = Ax\\), where \\(A\\) is a 2 x 2 matrix, the two columns of which are the base vectors of the 2-dimensional subspace.\nWe can still go about finding \\(p\\) in the same way as above:\n\\[\n\\begin{aligned}\nargmin_{x} (b - Ax)'(b - Ax) \\\\\n\\frac{d}{dx} (b - Ax)'(b - Ax) &= -2A'(b - Ax) = 0\n\\end{aligned}\n\\]\nSolving for \\(x\\) we get: \\[\n\\begin{aligned}\n-2A'(b - Ax) &= 0 \\\\\n-A'b + A'Ax &= 0 \\\\\nA'Ax &= A'b \\\\\nx &= (A'A)^{-1}A'b\n\\end{aligned}\n\\]\nThe last step above works only if \\(A'A\\) is actually invertible, which is the case if \\(A\\) has full rank, which is the case if none of its columns can be constructed from a linear combination of any other columns. (A visual way to think about this is the following: the columns of a matrix are the basis vectors of its column space. The rank is the number of dimensions of that column space. Full rank means that the column space has as many dimensions as there are columns.)\nThe math above generalises directly to projections onto N-dimensional space. All that changes is that \\(b\\), \\(A\\), \\(x\\), and \\(p\\) are higher-dimensional objects, and that visualising what’s happening becomes rather mind-bending."
  },
  {
    "objectID": "chapters/projection.html#useful-references",
    "href": "chapters/projection.html#useful-references",
    "title": "2  Projection",
    "section": "2.4 Useful references",
    "text": "2.4 Useful references\n\nGilbert Strang’s linear algebra lectures at MIT\n10 Fundamental Theorems for Econometrics"
  },
  {
    "objectID": "chapters/regression.html#the-setup",
    "href": "chapters/regression.html#the-setup",
    "title": "6  Regression",
    "section": "6.2 The setup",
    "text": "6.2 The setup\nWe usually start with data of the form \\(\\{y_i, x_{i1}, \\cdots, x_{ik}\\}_{i=1}^N\\), where we observe an outcome variable \\(y_i\\) and a set of \\(k\\) explanatory variables \\(x_i = (x_{i1}, \\cdots, x_{ik})\\) for each unit \\(i\\) in the dataset. We think that it might be reasonable to think of the outcome being linearly related to the regressors, so that, for each unit in our dataset, we can write the following linear equation:\n\\[\ny_{i} = \\beta_{1}x_{i1} + \\beta_{2}x_{i2} + ... + \\beta_{k}x_{ik} + \\epsilon_{i}\n\\]\nThis says that the outcome \\(y\\) can be thought of as a linear combination of all explanatory variables plus some error term.\nTODO: What makes this a “linear” equation: - The highest power to which any regressor is raised is 1 - The coefficients are constants, not variables - Regressors are related to one another using addition and subtraction only - The resulting line (in 2-D space), plane (in 3-D space) and hyperplane (in N-D space) are linear (the term linear equation originates from the simple case where there are two regressors, one of which is a constant, in which case we get a straight line in a Cartesian plane.)\nTODO: discuss all the assumptions we’re making here.\nTODO: Discuss the Angist & Pischke view of linear regression being good approximation even if relationship is not linear.\nWe thus have a system of linear equations of the form\n\\[\n\\begin{aligned}\ny_1 = \\beta_0 + \\beta_1 x_{1_1} + \\beta_2 x_{2_1} + \\ldots + \\beta_k x_{k_1} + \\epsilon_1 \\\\\ny_2 = \\beta_0 + \\beta_1 x_{1_2} + \\beta_2 x_{2_2} + \\ldots + \\beta_k x_{k_2} + \\epsilon_2 \\\\\n\\vdots\\\\\ny_n = \\beta_0 + \\beta_1 x_{1_n} + \\beta_2 x_{2_n} + \\ldots + \\beta_k x_{k_n} + \\epsilon_n \\\\\n\\end{aligned}\n\\]\nwhich we can rewrite in vector notation as\n\\[\n\\begin{aligned}\ny_1 = x_1'\\beta + \\epsilon_1 \\\\\ny_2 = x_2'\\beta + \\epsilon_2 \\\\\n\\vdots\\\\\ny_n = x_n'\\beta + \\epsilon_n,\n\\end{aligned}\n\\]\nwhere \\[\nx_i' = (x_{i1}, x_{i2}, \\ldots, x_{ik})\n\\]\nis a \\(1 \\times k\\) row vector that contains all \\(k\\) explanatory variables for each unit \\(i\\) and \\[ \\beta =\n\\begin{pmatrix}\n  \\beta_{1}\\\\\n  \\beta_{2}\\\\\n  \\vdots \\\\\n  \\beta_{k}\n\\end{pmatrix}\n\\]\nis a \\(k \\times 1\\) column vector that contains all \\(k\\) regression coefficients.\nTo be even more succinct, we can stack all n equations to get the matrix notation: \\[\n\\begin{equation}\ny = X\\beta + \\epsilon,\n\\end{equation}\n\\]\nwhere \\(\\beta\\) is defined as above,\n\\[ y =\n\\begin{pmatrix}\n  y_{1}\\\\\n  y_{2}\\\\\n  \\vdots \\\\\n  y_{k}\n\\end{pmatrix}\n\\]\nis a \\(n \\times 1\\) vector containing the \\(n\\) outcome variables, one for each unit in the data,\n\\[ X =\n\\begin{pmatrix}\n  x_{1}' \\\\\n  x_{2}' \\\\\n  \\vdots \\\\\n  x_{n}''\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n  x_{1,1} & x_{1,2} & \\cdots & x_{1,k} \\\\\n  x_{2,1} & x_{2,2} & \\cdots & x_{2,k} \\\\\n  \\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n  x_{n,1} & x_{n,2} & \\cdots & x_{n,k}\n\\end{pmatrix}\n\\]\nis an \\(n \\times k\\) matrix that contains all \\(n\\) row vectors \\(x_i'\\) stacked on top of each other, and\n\\[ \\epsilon =\n\\begin{pmatrix}\n  \\epsilon_{1}\\\\\n  \\epsilon_{2}\\\\\n  \\vdots \\\\\n  \\epsilon_{k}\n\\end{pmatrix}\n\\]\na column vector containing the \\(n\\) error terms.\n## The problem\nSo, what do we want to do here? We have data on an outcome variable \\(y\\) and explanatory variables \\(x\\) for each unit \\(i\\), and we think that it is reasonable to think that this data is generated by a process whereby \\(y\\) is the result of a linear combination of the \\(x\\)s plus some noise, which we capture in the error term. The challenge is to find the right linear combination."
  },
  {
    "objectID": "chapters/regression.html#classic-motivation",
    "href": "chapters/regression.html#classic-motivation",
    "title": "3  Regression",
    "section": "3.3 Classic motivation",
    "text": "3.3 Classic motivation"
  },
  {
    "objectID": "chapters/regression.html#linear-algebra-motivation",
    "href": "chapters/regression.html#linear-algebra-motivation",
    "title": "3  Regression",
    "section": "3.4 Linear algebra motivation",
    "text": "3.4 Linear algebra motivation"
  },
  {
    "objectID": "chapters/regression.html#resources",
    "href": "chapters/regression.html#resources",
    "title": "6  Regression",
    "section": "6.5 Resources",
    "text": "6.5 Resources\n\nHayashi, Wooldridge, Verbeek, online resources"
  },
  {
    "objectID": "chapters/regression.html#glossary",
    "href": "chapters/regression.html#glossary",
    "title": "6  Regression",
    "section": "6.1 Glossary",
    "text": "6.1 Glossary\nTODO: - Linear regression vs OLS"
  },
  {
    "objectID": "chapters/regression.html#classic-motivation-of-the-solution",
    "href": "chapters/regression.html#classic-motivation-of-the-solution",
    "title": "6  Regression",
    "section": "6.3 Classic motivation of the solution",
    "text": "6.3 Classic motivation of the solution\nTODO"
  },
  {
    "objectID": "chapters/regression.html#linear-algebra-motivation-of-the-solution",
    "href": "chapters/regression.html#linear-algebra-motivation-of-the-solution",
    "title": "6  Regression",
    "section": "6.4 Linear algebra motivation of the solution",
    "text": "6.4 Linear algebra motivation of the solution\nNotice how our problem here is exactly akin to the motivation for orthogonal projection discussed in Chapter 2. There we had a system of linear equations of the form\n\\[\nAx = b\n\\]\nwhich was overdetermined because the number of equations exceeded the number of unknowns. Our setup is equivalent. We have \\(n\\) equations and \\(k\\) unknowns (the \\(\\beta\\)s), so that – in practice – there will be no solution to the system:\n\\[\nX\\beta = y.\n\\]\nIn other words, there is no choice of \\(\\beta\\) that would linearly combine all the explanatory variables in each equation such that the result would be exactly \\(y\\). We account for this by adding the error term \\(\\epsilon\\), so that we have\n\\[\nX\\beta + \\epsilon = y.\n\\]\nWhat we do, now, is to say that we want to find that linear combination of the explanatory variables that is closest to \\(y\\), so that \\(\\epsilon\\) is as small as possible, which is the same as finding the orthogonal projection of \\(y\\) onto \\(X\\), which, traditionally, we call \\(\\hat{y}\\).\nThe solution is then the same as in Chapter 2:1\n\\[\n\\begin{aligned}\nX'\\epsilon &= 0 \\\\\nX'(y - \\hat{y}) &= 0 \\\\\nX'(y - X\\beta) &= 0 \\\\\nX'y - X'X\\beta &= 0 \\\\\nX'X\\beta &= X'y \\\\\n\\beta &= (X'X)^{-1}X'y\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "chapters/regression.html#footnotes",
    "href": "chapters/regression.html#footnotes",
    "title": "6  Regression",
    "section": "",
    "text": "One thing I would always wonder about in textbook is how I knew that the condition was \\(X'\\epsilon\\) instead of \\(\\epsilon'X\\). The answer is that in cases where order doesn’t matter, texts tend to choose what is more convenient for the math. We could solve \\(\\epsilon'X\\): \\[\n\\begin{aligned}\n\\epsilon'X &= 0 \\\\\n(y - \\hat{y})'X &= 0 \\\\\n(y - X\\beta)'X &= 0 \\\\\n(y' - \\beta'X')X &= 0 \\\\\ny'X - \\beta'X'X &= 0 \\\\\n\\beta'X'X &= y'X \\\\\n(\\beta'X'X)' &= (y'X)' \\\\\nX'X\\beta &= X'y \\\\\n\\beta &= (X'X)^{-1}X'y\n\\end{aligned}\n\\] which gets us to the same result but in more steps.↩︎"
  },
  {
    "objectID": "chapters/cuped.html#how-cuped-works",
    "href": "chapters/cuped.html#how-cuped-works",
    "title": "4  Variance reduction",
    "section": "4.3 How CUPED works",
    "text": "4.3 How CUPED works\nImagine that in addition to our outcome metric \\(y\\), we have access to another variable, \\(x\\), which is correlated with \\(y\\) but uncorrelated with the treatment assignment of our experiment – the most obvious candidate that has been found to work well is pre-experiment data of the metric of interest.\nWe can then create a new variable\n\\[\n\\tilde{y} = y - \\theta x,\n\\]\nwhere – it turns out – the optimal choice for \\(\\theta\\) is \\(\\frac{cov(y, x)}{var(x)}\\), which we can easily calculate from the available data.\nThis is useful because it can be shown that if we now evaluate our experiment using \\(\\tilde{y}\\) instead of \\(y\\), the treatment estimate will be the same but it’s standard error will be lower, which will increase power. The standard error of the treatment effect estimate is lower because the variance of \\(\\tilde{y}\\) is lower than that of \\(y\\) whenever \\(cov(y, x) \\neq 0\\), that is, whenever \\(x\\) and \\(y\\) are indeed correlated. To be precise, we have:\n\\[\nvar(\\tilde{y}) = var(y)(1 - \\rho^2),\n\\]\nwhere \\(\\rho\\) is the Pearson correlation between \\(x\\) and \\(y\\):\n\\[\n\\rho = \\frac{cov(y, x)}{var(x)var(y)}.\n\\]\n\\(\\hat{\\tau}^{cuped}\\) is unbiased:\n\\[\n\\begin{align*}\n\\mathbb{E}\\left[\\hat{\\tau}^{cuped}\\right] &= \\mathbb{E}\\left[\\bar{Y}^{cuped}_t - \\bar{Y}^{cuped}_c\\right] \\\\\n&= \\mathbb{E}\\left[\\left(\\bar{Y}_t - \\theta \\bar{X}_t + \\theta \\mathbb{E}X\\right) - \\left(\\bar{Y}_c - \\theta \\bar{X}_c + \\theta \\mathbb{E}X\\right)\\right] \\\\\n&= \\mathbb{E}\\left[\\left(\\bar{Y}_t - \\theta \\bar{X}_t\\right) - \\left(\\bar{Y}_c - \\theta \\bar{X}_c\\right)\\right] \\\\\n&= \\mathbb{E}\\left[\\bar{Y}_t - \\bar{Y}_c\\right] \\\\\n&= \\mathbb{E}\\left[\\frac{1}{N_t}\\sum_{\\text{i:T=1}}Y_i- \\frac{1}{N_c}\\sum_{\\text{i:T=0}}Y_i\\right] \\\\\n&= \\frac{1}{N_t} N_t \\mathbb{E}Y_t - \\frac{1}{N_c} N_c \\mathbb{E}Y_c \\\\\n&= \\mathbb{E}Y_t - \\mathbb{E}Y_c \\\\\n&= \\bar{Y}_t - \\bar{Y}_c \\\\\n&= \\tau\n\\end{align*}\n\\]\n\\(\\hat{\\tau}^{cuped}\\) has variance:\n\\[\n\\begin{align*}\n\\mathbb{V}\\left(\\hat{\\tau}^{cuped}\\right) &= \\mathbb{V}\\left(\\bar{Y}^{cuped}_t - \\bar{Y}^{cuped}_c\\right) \\\\\n&= \\mathbb{V}\\left(\\bar{Y}^{cuped}_t\\right) + \\mathbb{V}\\left(\\bar{Y}^{cuped}_c\\right) \\\\\n&= \\mathbb{V}\\left(\\bar{Y}_t - \\theta \\bar{X}_t + \\theta \\mathbb{E}X\\right) + \\mathbb{V}\\left(\\bar{Y}_c - \\theta \\bar{X}_c + \\theta\n\\mathbb{E}X\\right) \\\\\n&= \\mathbb{V}\\left(\\bar{Y}_t - \\theta \\bar{X}_t\\right) + \\mathbb{V}\\left(\\bar{Y}_c - \\theta \\bar{X}_c\\right) \\\\\n&= \\frac{1}{N_t}\\mathbb{V}\\left(Y_t - \\theta X_t\\right) + \\frac{1}{N_c}\\mathbb{V}\\left(Y_c - \\theta X_c\\right) \\\\\n&= \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) + \\theta^2 \\mathbb{V}(X_t) - 2\\theta Cov(Y_t, X_t)\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) + \\theta^2 \\mathbb{V}(X_c) - 2\\theta Cov(Y_c, X_c)\\right]\n\\end{align*}\n\\]\nThis is minimised for:\n\\[\n\\theta^* = \\frac{Cov(Y_t, X_t) + Cov(Y_c, X_c)}{\\mathbb{V}(X_t) + \\mathbb{V}(X_c)}\n\\]\nIn practice, a common approach is to pool the data to get:\n\\[\n\\begin{align*}\n\\theta^*_p &= \\frac{Cov(Y, X) + Cov(Y, X)}{\\mathbb{V}(X) + \\mathbb{V}(X)}\\\\\n&= \\frac{Cov(Y, X)}{\\mathbb{V}(X)},\n\\end{align*}\n\\]\nand to assume that \\(\\mathbb{V}(X_t) \\simeq \\mathbb{V}(X_t)\\), and \\(Cov(Y_t, X_t) \\simeq Cov(Y_c, X_c)\\), which is reasonable as long as the treatment effect is not too large (see discussion towards the end here). If, in addition, we let \\(\\rho = Cor(X, Y)\\), then we have\n\\[\n\\begin{align*}\n\\mathbb{V}\\left(\\hat{\\tau}^{cuped}\\right) &\\simeq \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) + (\\theta^*_p)^2 \\mathbb{V}(X) - 2 \\theta^*_p Cov(Y, X)\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) + (\\theta^*_p)^2 \\mathbb{V}(X) - 2 \\theta^*_p Cov(Y, X)\\right]\\\\\n&= \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) + \\left(\\frac{Cov(Y, X)}{\\mathbb{V}(X)}\\right)^2 \\mathbb{V}(X) - 2 \\left(\\frac{Cov(Y, X)}{\\mathbb{V}(X)}\\right) Cov(Y, X)\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) + \\left(\\frac{Cov(Y, X)}{\\mathbb{V}(X)}\\right)^2 \\mathbb{V}(X) - 2 \\left(\\frac{Cov(Y, X)}{\\mathbb{V}(X)}\\right) Cov(Y, X)\\right]\\\\\n&= \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) - \\frac{Cov(Y, X)^2}{\\mathbb{V}(X)}\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) - \\frac{Cov(Y, X)^2}{\\mathbb{V}(X)}\\right]\\\\\n&= \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) - \\frac{\\left(\\rho\\sqrt{\\mathbb{V}(X)}\\sqrt{\\mathbb{V}(Y)}\\right)^2}{\\mathbb{V}(X)}\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) - \\frac{\\left(\\rho\\sqrt{\\mathbb{V}(X)}\\sqrt{\\mathbb{V}(Y)}\\right)^2}{\\mathbb{V}(X)}\\right]\\\\\n&= \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) - \\rho^2\\mathbb{V}(Y)\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) - \\rho^2\\mathbb{V}(Y)\\right]\\\\\n&= \\frac{\\mathbb{V}(Y_t)}{N_t}(1 - \\rho^2) + \\frac{\\mathbb{V}(Y_c)}{N_c}(1 - \\rho^2)\\\\\n&= \\left[\\frac{\\mathbb{V}(Y_t)}{N_t} + \\frac{\\mathbb{V}(Y_c)}{N_c}\\right]\\left(1 - \\rho^2\\right)\n\\end{align*}\n\\]\nIn practice, we use the sample variances \\(s_t = \\frac{1}{N_t - 1}\\sum_{\\text{i:T=1}}\\left(Y_i - \\bar{Y}_t^{obs}\\right)^2\\) and \\(s_c = \\frac{1}{N_c - 1}\\sum_{\\text{i:T=0}}\\left(Y_i - \\bar{Y}_c^{obs}\\right)^2\\) as unbiased estimators for the variances of treatment and control outcomes, and a sample estimate of the correlation coefficient, \\(\\rho\\).\nThings to notice\n\nThe main “trick” CUPED relies on for unbiasedness is the fact that we don’t actually have to know \\(\\mathbb{E}X\\) to obtain an unbiased estimator since it cancels out when we take the difference of two CUPED-adjusted variables.\nAny fixed value of \\(\\theta\\) will give us an unbiased estimator of \\(\\tau\\), so pooling the data and assuming equal variances and covariances in the treatment and control groups, as we did to calculate the variance, effect the degree of variance reduction only. If we didn’t make these assumptions, the factor by which CUPED reduces variance would be a more complicated term than \\(\\left(1 - \\rho^2\\right)\\), involving separte variances and covariances from the treatment and control groups."
  },
  {
    "objectID": "chapters/cuped.html#is-cuped-regression-adjustment",
    "href": "chapters/cuped.html#is-cuped-regression-adjustment",
    "title": "4  Variance reduction",
    "section": "4.5 Is CUPED regression adjustment?",
    "text": "4.5 Is CUPED regression adjustment?\ntodo: - Is CUPED regression adjustment? Identical to regression only in simple case (show FWL link – have separate post on understanding FWL with relevant regression examples)\n\nTake inclusion of constant into accound (centering variables, but doesn’t change correlations)\n\nIt turns out that in the simple cases discussed above, it doesn’t – the two approaches are identical! Seeing why requires a few steps.\nFirst, we know (from the Frisch-Waugh-Lowell theorem) that if we were to estimate the alternative model\n\\[\n\\begin{equation}\n\\tilde{y}_i = \\alpha + \\beta_1^* \\tilde{d}_i + \\epsilon_i,\n\\end{equation}\n\\]\nwhere \\(\\tilde{y}_i\\) is the residual from regressing \\(y\\) on \\(x\\), and \\(\\tilde{d}_i\\) the residual from regressing \\(d\\) on \\(x\\), we would find that \\(\\beta_1^* = \\beta_1\\). That is, the two models are identical.\nSecond, to obtain \\(\\tilde{y}\\), we first estimate\n\\[\ny = \\alpha + \\delta x_i + u_i,\n\\]\nand then calculate \\(\\tilde{y} = y - \\delta x\\) (the calculation of \\(\\tilde{d}_i\\) works analogously). Given that this is a simple regression model, we know that \\(\\delta = \\frac{cov(y, x)}{var(x)}\\) so that\n\\[\n\\tilde{y} = y - \\frac{cov(y, x)}{var(x)}x.\n\\]\nFinally, above in our discussion of CUPED we have seen that the CUPED-adjusted outcome metric \\(\\tilde{y}\\) is defined in exactly the same way. Hence, to evaluate an experiment with a CUPED-adjusted outcome, we would estimate the model:\n\\[\n\\tilde{y}_i = \\alpha + \\beta^* d_i + \\epsilon_i^*,\n\\]\nNotice that the only difference to model (2) is that we don’t adjust the treatment assignment – we use \\(d_i\\) instead of \\(\\tilde{d}_i\\). But if the treatment assignment is random, then \\(cov(d, x) = 0\\) so that the adjustment has no effect and we have \\(\\tilde{d}_i = d_i\\). Hence, the two approaches are the same.\nIn general, regression adjustment and CUPED are identical if two conditions hold: (1) the treatment indicator is independent of \\(x\\), and (2) we use a linear CUPED adjustment. In the context of experimentation, where treatment is random, and with the classical (linear) CUPED adjustment discussed above, this is always the case.\nThe reason why in practice we get a don’t get the exact same result is that the covariance of \\(d\\) and \\(x\\) is only approximately 0, hence providing very similar, but not identical results."
  },
  {
    "objectID": "chapters/cuped.html",
    "href": "chapters/cuped.html",
    "title": "4  Regression adjustment",
    "section": "",
    "text": "5 CUPED\nCUPED stands for “Controlled experiments Using Pre-Experiment Data”, and reduces variance by partialling out as much variance as possible from the outcome metric using appropriate available data, usually data from the pre-experiment period – hence the name.\nNew framing\nCUPED is a re-invention of multiple linear regression. Evan Miller (here) and Matteo Courthoud (here) make similar points in their excellent posts on the topic, but – given my starting point – neither quite helped me fully understand what is going on. This post is my attempt to do that.\nIn particular, I think that to really understand the connection between multiple linear regression and CUPED, you have to understand the linear algebra of the Frisch-Waugh-Lowell theorem (FWL) rather than just knowing that that theorem says, and to understand that, you have to understand the concept of a projection. The latter two are both well explained in Thomas S. Robinson’s wonderful online book 10 Fundamental Theorems for Econometrics, on which I draw heavily."
  },
  {
    "objectID": "chapters/cuped.html#regression-adjustment",
    "href": "chapters/cuped.html#regression-adjustment",
    "title": "4  Variance reduction",
    "section": "4.1 Regression adjustment",
    "text": "4.1 Regression adjustment\nRegression adjustment reduces variance by adding additional regressors to the regression model used to evaluate an experiment in order to reduce residual variance.\nHow it works\nTo evaluate an experiment where we have, for each unit \\(i\\), an outcome metric \\(y_i\\) and a treatment assignment indicator \\(d_i\\) we would estimate the following linear regression model using OLS:\n\\[\ny_i = \\alpha + \\beta d_i + \\epsilon_i,\n\\]\nwhere \\(\\epsilon_i\\) is the error term, and where the estimate of \\(\\beta\\) is the estimate of our average treatment effect. If we have an additional variable, \\(x_i\\), that is correlated with \\(y_i\\) but uncorrelated with \\(d_i\\), we can add that to the right hand side of our regression model and estimate:\n\\[\n\\begin{equation}\ny_i = \\alpha + \\beta_1 d_i + \\beta_2 x_i + \\mu_i.\n\\end{equation}\n\\]\nIf \\(x\\) is uncorrelated with the treatment assignment then \\(\\beta = \\beta_1\\), so the average treatment effect estimate will remain unchanged, which is good. And if \\(x\\) is correlated with \\(y\\), then the standard error of the average treatment effect estimate will again be lower, which increases power.\n\n4.1.1 Useful resources\n\nImbens & Rubin, Causal Inference for Statistics, Social, and Biomedical Sciences, Chapter 7 link"
  },
  {
    "objectID": "chapters/cuped.html#cuped",
    "href": "chapters/cuped.html#cuped",
    "title": "4  Variance reduction",
    "section": "4.2 CUPED",
    "text": "4.2 CUPED\nCUPED stands for “Controlled experiments Using Pre-Experiment Data”, and reduces variance by partialling out outcome metric variance based on pre-experiment data.\nCUPED is a re-invention of multiple linear regression. Evan Miller (here) and Matteo Courthoud (here) make similar points in their excellent posts on the topic, but – given my starting point – neither quite helped me fully understand what is going on. This post is my attempt to do that.\nIn particular, I think that to really understand the connection between multiple linear regression and CUPED, you have to understand the linear algebra of the Frisch-Waugh-Lowell theorem (FWL) rather than just knowing that that theorem says, and to understand that, you have to understand the concept of a projection. The latter two are both well explained in Thomas S. Robinson’s wonderful online book 10 Fundamental Theorems for Econometrics, on which I draw heavily.\n\n4.2.1 How CUPED works\nImagine that in addition to our outcome metric \\(y\\), we have access to another variable, \\(x\\), which is correlated with \\(y\\) but uncorrelated with the treatment assignment of our experiment – the most obvious candidate that has been found to work well is pre-experiment data of the metric of interest.\nWe can then create a new variable\n\\[\n\\tilde{y} = y - \\theta x,\n\\]\nwhere – it turns out – the optimal choice for \\(\\theta\\) is \\(\\frac{cov(y, x)}{var(x)}\\), which we can easily calculate from the available data.\nThis is useful because it can be shown that if we now evaluate our experiment using \\(\\tilde{y}\\) instead of \\(y\\), the treatment estimate will be the same but it’s standard error will be lower, which will increase power. The standard error of the treatment effect estimate is lower because the variance of \\(\\tilde{y}\\) is lower than that of \\(y\\) whenever \\(cov(y, x) \\neq 0\\), that is, whenever \\(x\\) and \\(y\\) are indeed correlated. To be precise, we have:\n\\[\nvar(\\tilde{y}) = var(y)(1 - \\rho^2),\n\\]\nwhere \\(\\rho\\) is the Pearson correlation between \\(x\\) and \\(y\\):\n\\[\n\\rho = \\frac{cov(y, x)}{var(x)var(y)}.\n\\]\n\\(\\hat{\\tau}^{cuped}\\) is unbiased:\n\\[\n\\begin{align*}\n\\mathbb{E}\\left[\\hat{\\tau}^{cuped}\\right] &= \\mathbb{E}\\left[\\bar{Y}^{cuped}_t - \\bar{Y}^{cuped}_c\\right] \\\\\n&= \\mathbb{E}\\left[\\left(\\bar{Y}_t - \\theta \\bar{X}_t + \\theta \\mathbb{E}X\\right) - \\left(\\bar{Y}_c - \\theta \\bar{X}_c + \\theta \\mathbb{E}X\\right)\\right] \\\\\n&= \\mathbb{E}\\left[\\left(\\bar{Y}_t - \\theta \\bar{X}_t\\right) - \\left(\\bar{Y}_c - \\theta \\bar{X}_c\\right)\\right] \\\\\n&= \\mathbb{E}\\left[\\bar{Y}_t - \\bar{Y}_c\\right] \\\\\n&= \\mathbb{E}\\left[\\frac{1}{N_t}\\sum_{\\text{i:T=1}}Y_i- \\frac{1}{N_c}\\sum_{\\text{i:T=0}}Y_i\\right] \\\\\n&= \\frac{1}{N_t} N_t \\mathbb{E}Y_t - \\frac{1}{N_c} N_c \\mathbb{E}Y_c \\\\\n&= \\mathbb{E}Y_t - \\mathbb{E}Y_c \\\\\n&= \\bar{Y}_t - \\bar{Y}_c \\\\\n&= \\tau\n\\end{align*}\n\\]\n\\(\\hat{\\tau}^{cuped}\\) has variance:\n\\[\n\\begin{align*}\n\\mathbb{V}\\left(\\hat{\\tau}^{cuped}\\right) &= \\mathbb{V}\\left(\\bar{Y}^{cuped}_t - \\bar{Y}^{cuped}_c\\right) \\\\\n&= \\mathbb{V}\\left(\\bar{Y}^{cuped}_t\\right) + \\mathbb{V}\\left(\\bar{Y}^{cuped}_c\\right) \\\\\n&= \\mathbb{V}\\left(\\bar{Y}_t - \\theta \\bar{X}_t + \\theta \\mathbb{E}X\\right) + \\mathbb{V}\\left(\\bar{Y}_c - \\theta \\bar{X}_c + \\theta\n\\mathbb{E}X\\right) \\\\\n&= \\mathbb{V}\\left(\\bar{Y}_t - \\theta \\bar{X}_t\\right) + \\mathbb{V}\\left(\\bar{Y}_c - \\theta \\bar{X}_c\\right) \\\\\n&= \\frac{1}{N_t}\\mathbb{V}\\left(Y_t - \\theta X_t\\right) + \\frac{1}{N_c}\\mathbb{V}\\left(Y_c - \\theta X_c\\right) \\\\\n&= \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) + \\theta^2 \\mathbb{V}(X_t) - 2\\theta Cov(Y_t, X_t)\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) + \\theta^2 \\mathbb{V}(X_c) - 2\\theta Cov(Y_c, X_c)\\right]\n\\end{align*}\n\\]\nThis is minimised for:\n\\[\n\\theta^* = \\frac{Cov(Y_t, X_t) + Cov(Y_c, X_c)}{\\mathbb{V}(X_t) + \\mathbb{V}(X_c)}\n\\]\nIn practice, a common approach is to pool the data to get:\n\\[\n\\begin{align*}\n\\theta^*_p &= \\frac{Cov(Y, X) + Cov(Y, X)}{\\mathbb{V}(X) + \\mathbb{V}(X)}\\\\\n&= \\frac{Cov(Y, X)}{\\mathbb{V}(X)},\n\\end{align*}\n\\]\nand to assume that \\(\\mathbb{V}(X_t) \\simeq \\mathbb{V}(X_t)\\), and \\(Cov(Y_t, X_t) \\simeq Cov(Y_c, X_c)\\), which is reasonable as long as the treatment effect is not too large (see discussion towards the end here). If, in addition, we let \\(\\rho = Cor(X, Y)\\), then we have\n\\[\n\\begin{align*}\n\\mathbb{V}\\left(\\hat{\\tau}^{cuped}\\right) &\\simeq \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) + (\\theta^*_p)^2 \\mathbb{V}(X) - 2 \\theta^*_p Cov(Y, X)\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) + (\\theta^*_p)^2 \\mathbb{V}(X) - 2 \\theta^*_p Cov(Y, X)\\right]\\\\\n&= \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) + \\left(\\frac{Cov(Y, X)}{\\mathbb{V}(X)}\\right)^2 \\mathbb{V}(X) - 2 \\left(\\frac{Cov(Y, X)}{\\mathbb{V}(X)}\\right) Cov(Y, X)\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) + \\left(\\frac{Cov(Y, X)}{\\mathbb{V}(X)}\\right)^2 \\mathbb{V}(X) - 2 \\left(\\frac{Cov(Y, X)}{\\mathbb{V}(X)}\\right) Cov(Y, X)\\right]\\\\\n&= \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) - \\frac{Cov(Y, X)^2}{\\mathbb{V}(X)}\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) - \\frac{Cov(Y, X)^2}{\\mathbb{V}(X)}\\right]\\\\\n&= \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) - \\frac{\\left(\\rho\\sqrt{\\mathbb{V}(X)}\\sqrt{\\mathbb{V}(Y)}\\right)^2}{\\mathbb{V}(X)}\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) - \\frac{\\left(\\rho\\sqrt{\\mathbb{V}(X)}\\sqrt{\\mathbb{V}(Y)}\\right)^2}{\\mathbb{V}(X)}\\right]\\\\\n&= \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) - \\rho^2\\mathbb{V}(Y)\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) - \\rho^2\\mathbb{V}(Y)\\right]\\\\\n&= \\frac{\\mathbb{V}(Y_t)}{N_t}(1 - \\rho^2) + \\frac{\\mathbb{V}(Y_c)}{N_c}(1 - \\rho^2)\\\\\n&= \\left[\\frac{\\mathbb{V}(Y_t)}{N_t} + \\frac{\\mathbb{V}(Y_c)}{N_c}\\right]\\left(1 - \\rho^2\\right)\n\\end{align*}\n\\]\nIn practice, we use the sample variances \\(s_t = \\frac{1}{N_t - 1}\\sum_{\\text{i:T=1}}\\left(Y_i - \\bar{Y}_t^{obs}\\right)^2\\) and \\(s_c = \\frac{1}{N_c - 1}\\sum_{\\text{i:T=0}}\\left(Y_i - \\bar{Y}_c^{obs}\\right)^2\\) as unbiased estimators for the variances of treatment and control outcomes, and a sample estimate of the correlation coefficient, \\(\\rho\\).\nThings to notice\n\nThe main “trick” CUPED relies on for unbiasedness is the fact that we don’t actually have to know \\(\\mathbb{E}X\\) to obtain an unbiased estimator since it cancels out when we take the difference of two CUPED-adjusted variables.\nAny fixed value of \\(\\theta\\) will give us an unbiased estimator of \\(\\tau\\), so pooling the data and assuming equal variances and covariances in the treatment and control groups, as we did to calculate the variance, effect the degree of variance reduction only. If we didn’t make these assumptions, the factor by which CUPED reduces variance would be a more complicated term than \\(\\left(1 - \\rho^2\\right)\\), involving separte variances and covariances from the treatment and control groups.\n\n\n\n4.2.2 Features of CUPED\n\nAlso permits non-linear adjustments (i.e. not reliant on linearity assumptions in OLS)\n\n\n\n4.2.3 Is CUPED regression adjustment?\ntodo: - Is CUPED regression adjustment? Identical to regression only in simple case (show FWL link – have separate post on understanding FWL with relevant regression examples)\n\nTake inclusion of constant into accound (centering variables, but doesn’t change correlations)\n\nIt turns out that in the simple cases discussed above, it doesn’t – the two approaches are identical! Seeing why requires a few steps.\nFirst, we know (from the Frisch-Waugh-Lowell theorem) that if we were to estimate the alternative model\n\\[\n\\begin{equation}\n\\tilde{y}_i = \\alpha + \\beta_1^* \\tilde{d}_i + \\epsilon_i,\n\\end{equation}\n\\]\nwhere \\(\\tilde{y}_i\\) is the residual from regressing \\(y\\) on \\(x\\), and \\(\\tilde{d}_i\\) the residual from regressing \\(d\\) on \\(x\\), we would find that \\(\\beta_1^* = \\beta_1\\). That is, the two models are identical.\nSecond, to obtain \\(\\tilde{y}\\), we first estimate\n\\[\ny = \\alpha + \\delta x_i + u_i,\n\\]\nand then calculate \\(\\tilde{y} = y - \\delta x\\) (the calculation of \\(\\tilde{d}_i\\) works analogously). Given that this is a simple regression model, we know that \\(\\delta = \\frac{cov(y, x)}{var(x)}\\) so that\n\\[\n\\tilde{y} = y - \\frac{cov(y, x)}{var(x)}x.\n\\]\nFinally, above in our discussion of CUPED we have seen that the CUPED-adjusted outcome metric \\(\\tilde{y}\\) is defined in exactly the same way. Hence, to evaluate an experiment with a CUPED-adjusted outcome, we would estimate the model:\n\\[\n\\tilde{y}_i = \\alpha + \\beta^* d_i + \\epsilon_i^*,\n\\]\nNotice that the only difference to model (2) is that we don’t adjust the treatment assignment – we use \\(d_i\\) instead of \\(\\tilde{d}_i\\). But if the treatment assignment is random, then \\(cov(d, x) = 0\\) so that the adjustment has no effect and we have \\(\\tilde{d}_i = d_i\\). Hence, the two approaches are the same.\nIn general, regression adjustment and CUPED are identical if two conditions hold: (1) the treatment indicator is independent of \\(x\\), and (2) we use a linear CUPED adjustment. In the context of experimentation, where treatment is random, and with the classical (linear) CUPED adjustment discussed above, this is always the case.\nThe reason why in practice we get a don’t get the exact same result is that the covariance of \\(d\\) and \\(x\\) is only approximately 0, hence providing very similar, but not identical results.\n\n\n4.2.4 Is CUPED DiD?\n\nIs CUPED DiD? (based on Courthoud) – same if theta = 1\n\n### Useful resources\n\nDeng et al. 2013 – original CUPED paper – the original paper\nVariance reduction section of Deng’s causal inference book – more in-depth discussion of some aspects of CUPED and its link to regression adjustment\nYou can’t spell CUPED without Frisch-Waugh-Lovell – good post exploring link to FWL theorem\nUnderstanding CUPED – good post exploring link to multiple regression (also using FWL theorem) and DiD.\nCUPED on Statsig\nEPPO posts on CUPED here and here"
  },
  {
    "objectID": "chapters/cuped.html#features-of-cuped",
    "href": "chapters/cuped.html#features-of-cuped",
    "title": "4  Variance reduction",
    "section": "4.4 Features of CUPED",
    "text": "4.4 Features of CUPED\n\nAlso permits non-linear adjustments (i.e. not reliant on linearity assumptions in OLS)"
  },
  {
    "objectID": "chapters/cuped.html#is-cuped-did",
    "href": "chapters/cuped.html#is-cuped-did",
    "title": "4  Variance reduction",
    "section": "4.6 Is CUPED DiD?",
    "text": "4.6 Is CUPED DiD?\n\nIs CUPED DiD? (based on Courthoud) – same if theta = 1\n\n### Useful resources\n\nDeng et al. 2013 – original CUPED paper – the original paper\nVariance reduction section of Deng’s causal inference book – more in-depth discussion of some aspects of CUPED and its link to regression adjustment\nYou can’t spell CUPED without Frisch-Waugh-Lovell – good post exploring link to FWL theorem\nUnderstanding CUPED – good post exploring link to multiple regression (also using FWL theorem) and DiD.\nCUPED on Statsig\nEPPO posts on CUPED here and here"
  },
  {
    "objectID": "chapters/variance_reduction.html#why-reduce-variance",
    "href": "chapters/variance_reduction.html#why-reduce-variance",
    "title": "7  Variance reduction",
    "section": "7.1 Why reduce variance?",
    "text": "7.1 Why reduce variance?\nTODO: - Explain that we wanna increase power (refer to power section) - Reducing variance is one way to increase power (often the only feasible one)\nThe estimand of interest is the population average treatment effect:\n\\[\n\\tau = \\bar{y}_t - \\bar{y}_c.\n\\]\nUnder random treatment assignment, an unbiased estimator of \\(\\tau\\) is the difference in means between treatment and control units in the sample:\n\\[\n\\hat{\\tau}^{dif} = \\bar{y}_t^{obs} - \\bar{y}_c^{obs}.\n\\]\nThe variance of \\(\\hat{\\tau}^{dif}\\) is given by:\n\\[\n\\mathbb{V}(\\hat{\\tau}^{dif}) = \\frac{s_t}{N_t} + \\frac{s_c}{N_c},\n\\]\nwhere\n\\[\ns_t = \\frac{1}{N_t - 1}\\sum_{\\text{i:d=1}}(y_i - \\bar{y}_t^{obs})^2, \\quad s_c = \\frac{1}{N_c - 1}\\sum_{\\text{i:d=0}}(y_i - \\bar{y}_c^{obs})^2.\n\\]\nHence: for a given sample size, we can reduce \\(\\mathbb{V}(\\hat{\\tau}^{dif})\\) by reducing the variance in the outcome metric, \\(Y\\) – this is the variance we are trying to reduce."
  },
  {
    "objectID": "chapters/variance_reduction.html#regression-adjustment",
    "href": "chapters/variance_reduction.html#regression-adjustment",
    "title": "7  Variance reduction",
    "section": "7.4 Regression adjustment",
    "text": "7.4 Regression adjustment\nRegression adjustment reduces variance by adding additional regressors to the regression model used to evaluate an experiment in order to reduce residual variance.\nHow it works\nTo evaluate an experiment where we have, for each unit \\(i\\), an outcome metric \\(y_i\\) and a treatment assignment indicator \\(d_i\\) we would estimate the following linear regression model using OLS:\n\\[\ny_i = \\alpha + \\beta d_i + \\epsilon_i,\n\\]\nwhere \\(\\epsilon_i\\) is the error term, and where the estimate of \\(\\beta\\) is the estimate of our average treatment effect. If we have an additional variable, \\(x_i\\), that is correlated with \\(y_i\\) but uncorrelated with \\(d_i\\), we can add that to the right hand side of our regression model and estimate:\n\\[\n\\begin{equation}\ny_i = \\alpha + \\beta_1 d_i + \\beta_2 x_i + \\mu_i.\n\\end{equation}\n\\]\nIf \\(x\\) is uncorrelated with the treatment assignment then \\(\\beta = \\beta_1\\), so the average treatment effect estimate will remain unchanged, which is good. And if \\(x\\) is correlated with \\(y\\), then the standard error of the average treatment effect estimate will again be lower, which increases power.\n\n7.4.1 Useful resources\n\nImbens & Rubin, Causal Inference for Statistics, Social, and Biomedical Sciences, Chapter 7 link"
  },
  {
    "objectID": "chapters/variance_reduction.html#cuped",
    "href": "chapters/variance_reduction.html#cuped",
    "title": "7  Variance reduction",
    "section": "7.5 CUPED",
    "text": "7.5 CUPED\nCUPED stands for “Controlled experiments Using Pre-Experiment Data”, and reduces variance by partialling out outcome metric variance based on pre-experiment data.\n\n7.5.1 How CUPED works\nCUPED supposes that in addition to an outcome metric \\(y\\), we also have access to another variable, \\(x\\), which is correlated with \\(y\\) but uncorrelated with the treatment assignment of our experiment. Pre-experiment data of the outcome metric is a good candidate for \\(x\\) when it is available – it’s what’s commonly used, and where the method gets its name from. With that in hand, notice that we can write\n– the most obvious candidate that has been found to work well is pre-experiment data of the metric of interest.\nWe can then create a new variable\n\\[\n\\tilde{y} = y - \\theta x,\n\\]\nwhere – it turns out – the optimal choice for \\(\\theta\\) is \\(\\frac{cov(y, x)}{var(x)}\\), which we can easily calculate from the available data.\nThis is useful because it can be shown that if we now evaluate our experiment using \\(\\tilde{y}\\) instead of \\(y\\), the treatment estimate will be the same but it’s standard error will be lower, which will increase power. The standard error of the treatment effect estimate is lower because the variance of \\(\\tilde{y}\\) is lower than that of \\(y\\) whenever \\(cov(y, x) \\neq 0\\), that is, whenever \\(x\\) and \\(y\\) are indeed correlated. To be precise, we have:\n\\[\nvar(\\tilde{y}) = var(y)(1 - \\rho^2),\n\\]\nwhere \\(\\rho\\) is the Pearson correlation between \\(x\\) and \\(y\\):\n\\[\n\\rho = \\frac{cov(y, x)}{var(x)var(y)}.\n\\]\nPresentation notes:\n\nAssume that in addition to our outcome variable \\(Y\\), we have access to another random variable, \\(X\\), which is independent of the treatment assignment and has known expectation \\(\\mathbb{E}X\\).\nWe can then define \\(\\bar{Y}^{cuped} = \\bar{Y} - \\theta \\bar{X} + \\theta \\mathbb{E}X\\) for both treatment and control groups, and compare avearge outcomes in this adjusted metric.\nOur new estimator is: \\(\\hat{\\tau}^{cuped} = \\bar{Y}^{cuped}_t - \\bar{Y}^{cuped}_c\\).\n\\(\\hat{\\tau}^{cuped}\\) is unbiased since \\(\\mathbb{E}\\left[\\hat{\\tau}^{cuped}\\right] = \\bar{Y}_t - \\bar{Y}_c = \\tau\\) (proof in appendix below).\nIf treatment effects are small (which, in practice, they usually are) and for an optimal choice of \\(\\theta\\): \\(\\mathbb{V}\\left(\\hat{\\tau}^{cuped}\\right) \\simeq \\left(\\frac{s_t}{N_t} + \\frac{s_c}{N_c}\\right)\\left(1 - \\rho^2\\right)\\), where \\(\\rho\\) is the correlation coefficient of \\(Y\\) and \\(X\\).\nHence: \\(\\frac{\\mathbb{V}(\\hat{\\tau}^{cuped})}{\\mathbb{V}(\\hat{\\tau}^{dif})} = 1 - \\rho^2\\) – the higher the correlation between \\(Y\\) and \\(X\\), the more CUPED reduces the variance of our treatment estimate.\n\n\\(\\hat{\\tau}^{cuped}\\) is unbiased:\n\\[\n\\begin{align*}\n\\mathbb{E}\\left[\\hat{\\tau}^{cuped}\\right] &= \\mathbb{E}\\left[\\bar{Y}^{cuped}_t - \\bar{Y}^{cuped}_c\\right] \\\\\n&= \\mathbb{E}\\left[\\left(\\bar{Y}_t - \\theta \\bar{X}_t + \\theta \\mathbb{E}X\\right) - \\left(\\bar{Y}_c - \\theta \\bar{X}_c + \\theta \\mathbb{E}X\\right)\\right] \\\\\n&= \\mathbb{E}\\left[\\left(\\bar{Y}_t - \\theta \\bar{X}_t\\right) - \\left(\\bar{Y}_c - \\theta \\bar{X}_c\\right)\\right] \\\\\n&= \\mathbb{E}\\left[\\bar{Y}_t - \\bar{Y}_c\\right] \\\\\n&= \\mathbb{E}\\left[\\frac{1}{N_t}\\sum_{\\text{i:T=1}}Y_i- \\frac{1}{N_c}\\sum_{\\text{i:T=0}}Y_i\\right] \\\\\n&= \\frac{1}{N_t} N_t \\mathbb{E}Y_t - \\frac{1}{N_c} N_c \\mathbb{E}Y_c \\\\\n&= \\mathbb{E}Y_t - \\mathbb{E}Y_c \\\\\n&= \\bar{Y}_t - \\bar{Y}_c \\\\\n&= \\tau\n\\end{align*}\n\\]\n\\(\\hat{\\tau}^{cuped}\\) has variance:\n\\[\n\\begin{align*}\n\\mathbb{V}\\left(\\hat{\\tau}^{cuped}\\right) &= \\mathbb{V}\\left(\\bar{Y}^{cuped}_t - \\bar{Y}^{cuped}_c\\right) \\\\\n&= \\mathbb{V}\\left(\\bar{Y}^{cuped}_t\\right) + \\mathbb{V}\\left(\\bar{Y}^{cuped}_c\\right) \\\\\n&= \\mathbb{V}\\left(\\bar{Y}_t - \\theta \\bar{X}_t + \\theta \\mathbb{E}X\\right) + \\mathbb{V}\\left(\\bar{Y}_c - \\theta \\bar{X}_c + \\theta\n\\mathbb{E}X\\right) \\\\\n&= \\mathbb{V}\\left(\\bar{Y}_t - \\theta \\bar{X}_t\\right) + \\mathbb{V}\\left(\\bar{Y}_c - \\theta \\bar{X}_c\\right) \\\\\n&= \\frac{1}{N_t}\\mathbb{V}\\left(Y_t - \\theta X_t\\right) + \\frac{1}{N_c}\\mathbb{V}\\left(Y_c - \\theta X_c\\right) \\\\\n&= \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) + \\theta^2 \\mathbb{V}(X_t) - 2\\theta Cov(Y_t, X_t)\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) + \\theta^2 \\mathbb{V}(X_c) - 2\\theta Cov(Y_c, X_c)\\right]\n\\end{align*}\n\\]\nThis is minimised for:\n\\[\n\\theta^* = \\frac{Cov(Y_t, X_t) + Cov(Y_c, X_c)}{\\mathbb{V}(X_t) + \\mathbb{V}(X_c)}\n\\]\nIn practice, a common approach is to pool the data to get:\n\\[\n\\begin{align*}\n\\theta^*_p &= \\frac{Cov(Y, X) + Cov(Y, X)}{\\mathbb{V}(X) + \\mathbb{V}(X)}\\\\\n&= \\frac{Cov(Y, X)}{\\mathbb{V}(X)},\n\\end{align*}\n\\]\nand to assume that \\(\\mathbb{V}(X_t) \\simeq \\mathbb{V}(X_t)\\), and \\(Cov(Y_t, X_t) \\simeq Cov(Y_c, X_c)\\), which is reasonable as long as the treatment effect is not too large (see discussion towards the end here). If, in addition, we let \\(\\rho = Cor(X, Y)\\), then we have\n\\[\n\\begin{align*}\n\\mathbb{V}\\left(\\hat{\\tau}^{cuped}\\right) &\\simeq \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) + (\\theta^*_p)^2 \\mathbb{V}(X) - 2 \\theta^*_p Cov(Y, X)\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) + (\\theta^*_p)^2 \\mathbb{V}(X) - 2 \\theta^*_p Cov(Y, X)\\right]\\\\\n&= \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) + \\left(\\frac{Cov(Y, X)}{\\mathbb{V}(X)}\\right)^2 \\mathbb{V}(X) - 2 \\left(\\frac{Cov(Y, X)}{\\mathbb{V}(X)}\\right) Cov(Y, X)\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) + \\left(\\frac{Cov(Y, X)}{\\mathbb{V}(X)}\\right)^2 \\mathbb{V}(X) - 2 \\left(\\frac{Cov(Y, X)}{\\mathbb{V}(X)}\\right) Cov(Y, X)\\right]\\\\\n&= \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) - \\frac{Cov(Y, X)^2}{\\mathbb{V}(X)}\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) - \\frac{Cov(Y, X)^2}{\\mathbb{V}(X)}\\right]\\\\\n&= \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) - \\frac{\\left(\\rho\\sqrt{\\mathbb{V}(X)}\\sqrt{\\mathbb{V}(Y)}\\right)^2}{\\mathbb{V}(X)}\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) - \\frac{\\left(\\rho\\sqrt{\\mathbb{V}(X)}\\sqrt{\\mathbb{V}(Y)}\\right)^2}{\\mathbb{V}(X)}\\right]\\\\\n&= \\frac{1}{N_t}\\left[\\mathbb{V}(Y_t) - \\rho^2\\mathbb{V}(Y)\\right] + \\frac{1}{N_c}\\left[\\mathbb{V}(Y_c) - \\rho^2\\mathbb{V}(Y)\\right]\\\\\n&= \\frac{\\mathbb{V}(Y_t)}{N_t}(1 - \\rho^2) + \\frac{\\mathbb{V}(Y_c)}{N_c}(1 - \\rho^2)\\\\\n&= \\left[\\frac{\\mathbb{V}(Y_t)}{N_t} + \\frac{\\mathbb{V}(Y_c)}{N_c}\\right]\\left(1 - \\rho^2\\right)\n\\end{align*}\n\\]\nIn practice, we use the sample variances \\(s_t = \\frac{1}{N_t - 1}\\sum_{\\text{i:T=1}}\\left(Y_i - \\bar{Y}_t^{obs}\\right)^2\\) and \\(s_c = \\frac{1}{N_c - 1}\\sum_{\\text{i:T=0}}\\left(Y_i - \\bar{Y}_c^{obs}\\right)^2\\) as unbiased estimators for the variances of treatment and control outcomes, and a sample estimate of the correlation coefficient, \\(\\rho\\).\nThings to notice\n\nThe main “trick” CUPED relies on for unbiasedness is the fact that we don’t actually have to know \\(\\mathbb{E}X\\) to obtain an unbiased estimator since it cancels out when we take the difference of two CUPED-adjusted variables.\nAny fixed value of \\(\\theta\\) will give us an unbiased estimator of \\(\\tau\\), so pooling the data and assuming equal variances and covariances in the treatment and control groups, as we did to calculate the variance, effect the degree of variance reduction only. If we didn’t make these assumptions, the factor by which CUPED reduces variance would be a more complicated term than \\(\\left(1 - \\rho^2\\right)\\), involving separte variances and covariances from the treatment and control groups.\n\n\n\n7.5.2 Features of CUPED\n\nAlso permits non-linear adjustments (i.e. not reliant on linearity assumptions in OLS)\nReduces biase (see statsic post)\n\n\n\n7.5.3 Is CUPED regression adjustment?\ntodo: - Is CUPED regression adjustment? Identical to regression only in simple case (show FWL link – have separate post on understanding FWL with relevant regression examples)\n\nTake inclusion of constant into accound (centering variables, but doesn’t change correlations)\nShow that in multiple regression, var(Y_adjusted) = var(y_unadjusted)(1 - R^2) – so, CUPED result is just a specieal case where k = 1, in which case R^2 = rho.\n\nIt turns out that in the simple cases discussed above, it doesn’t – the two approaches are identical! Seeing why requires a few steps.\nFirst, we know (from the Frisch-Waugh-Lowell theorem) that if we were to estimate the alternative model\n\\[\n\\begin{equation}\n\\tilde{y}_i = \\alpha + \\beta_1^* \\tilde{d}_i + \\epsilon_i,\n\\end{equation}\n\\]\nwhere \\(\\tilde{y}_i\\) is the residual from regressing \\(y\\) on \\(x\\), and \\(\\tilde{d}_i\\) the residual from regressing \\(d\\) on \\(x\\), we would find that \\(\\beta_1^* = \\beta_1\\). That is, the two models are identical.\nSecond, to obtain \\(\\tilde{y}\\), we first estimate\n\\[\ny = \\alpha + \\delta x_i + u_i,\n\\]\nand then calculate \\(\\tilde{y} = y - \\delta x\\) (the calculation of \\(\\tilde{d}_i\\) works analogously). Given that this is a simple regression model, we know that \\(\\delta = \\frac{cov(y, x)}{var(x)}\\) so that\n\\[\n\\tilde{y} = y - \\frac{cov(y, x)}{var(x)}x.\n\\]\nFinally, above in our discussion of CUPED we have seen that the CUPED-adjusted outcome metric \\(\\tilde{y}\\) is defined in exactly the same way. Hence, to evaluate an experiment with a CUPED-adjusted outcome, we would estimate the model:\n\\[\n\\tilde{y}_i = \\alpha + \\beta^* d_i + \\epsilon_i^*,\n\\]\nNotice that the only difference to model (2) is that we don’t adjust the treatment assignment – we use \\(d_i\\) instead of \\(\\tilde{d}_i\\). But if the treatment assignment is random, then \\(cov(d, x) = 0\\) so that the adjustment has no effect and we have \\(\\tilde{d}_i = d_i\\). Hence, the two approaches are the same.\nIn general, regression adjustment and CUPED are identical if two conditions hold: (1) the treatment indicator is independent of \\(x\\), and (2) we use a linear CUPED adjustment. In the context of experimentation, where treatment is random, and with the classical (linear) CUPED adjustment discussed above, this is always the case.\nThe reason why in practice we get a don’t get the exact same result is that the covariance of \\(d\\) and \\(x\\) is only approximately 0, hence providing very similar, but not identical results.\n\n\n7.5.4 Is CUPED DiD?\n\nIs CUPED DiD? (based on Courthoud) – same if theta = 1\n\n\n\n7.5.5 Non-linear extensions"
  },
  {
    "objectID": "chapters/variance_reduction.html#blog-post-notes",
    "href": "chapters/variance_reduction.html#blog-post-notes",
    "title": "7  Variance reduction",
    "section": "7.6 Blog post notes",
    "text": "7.6 Blog post notes\nCUPED is a re-invention of multiple linear regression. Evan Miller (here) and Matteo Courthoud (here) make similar points in their excellent posts on the topic, but – given my starting point – neither quite helped me fully understand what is going on. This post is my attempt to do that.\nIn particular, I think that to really understand the connection between multiple linear regression and CUPED, you have to understand the linear algebra of the Frisch-Waugh-Lowell theorem (FWL) rather than just knowing that that theorem says, and to understand that, you have to understand the concept of a projection.\n\nThe motivation for CUPED seems to be a bit of a strawman: that regression adjustment relies on assumption that expectation of Y conditional on X is linear. Imbens and Rubin in 7.5 show that this is not required. Neither is homoskedasticity, or, rather, this should hold anyways given randomisation. Study chapter 7.\n\n### Useful resources\n\nDeng et al. 2013 – original CUPED paper – the original paper\nVariance reduction section of Deng’s causal inference book – more in-depth discussion of some aspects of CUPED and its link to regression adjustment\nYou can’t spell CUPED without Frisch-Waugh-Lovell – good post exploring link to FWL theorem\nUnderstanding CUPED – good post exploring link to multiple regression (also using FWL theorem) and DiD.\nReducing variance in A/B testing with CUPED\nCUPED on Statsig"
  },
  {
    "objectID": "chapters/variance_reduction.html#stratification",
    "href": "chapters/variance_reduction.html#stratification",
    "title": "7  Variance reduction",
    "section": "7.3 Stratification",
    "text": "7.3 Stratification\nTODO\n\n7.3.1 Useful resources\n\nDeng et al. 2013 – original CUPED paper – the original paper\nFive ways to reduce variance in A/B testing"
  },
  {
    "objectID": "chapters/variance_reduction.html#useful-resources-2",
    "href": "chapters/variance_reduction.html#useful-resources-2",
    "title": "7  Variance reduction",
    "section": "7.5 Useful resources",
    "text": "7.5 Useful resources\n\nFive ways to reduce variance in A/B testing\nOnline Experiments Tricks — Variance Reduction\nCUPED, CUPAC, and Other Ways to Reduce Variance in an Experiment\nDon’t use a t-test for A/B testing\nVariance Reduction in Experiments — Part 1: Intuition – see also part 2"
  },
  {
    "objectID": "chapters/variance_reduction.html#what-about-the-variance-bias-trade-off",
    "href": "chapters/variance_reduction.html#what-about-the-variance-bias-trade-off",
    "title": "7  Variance reduction",
    "section": "7.2 What about the variance-bias trade-off?",
    "text": "7.2 What about the variance-bias trade-off?\nDiscuss why we can reduce variance without increasing bias."
  },
  {
    "objectID": "chapters/variance_reduction.html#cupac",
    "href": "chapters/variance_reduction.html#cupac",
    "title": "7  Variance reduction",
    "section": "7.7 CUPAC",
    "text": "7.7 CUPAC\n\nCUPED can be extended to (make notation consistent with CUPED)\n\n\\[\ny' = y - \\theta \\bar{f(X)} + \\theta E(f(X))\n\\]\n\nIn above, it can be shown that optimal \\(f(X) = E(Y|X)\\) (show this).\nCUPED, which is effectively regression adjustment, uses best linear predictor.\nCUPAC extends this to non-linear predictors, generating \\(\\hat{y} = g(X) = E(Y|X)\\)."
  },
  {
    "objectID": "chapters/fisher.html",
    "href": "chapters/fisher.html",
    "title": "3  Fisher’s approach",
    "section": "",
    "text": "Fisher’s aim in his original work on experimentation was to asses the sharp (or exact) null hypothesis – the hypothesis that a treatment had no effect whatsoever, meaning that the potential outcomes for being treated and not treated are the same for each unit in the data.[^hypothesis]\nUnter that null hypothesis the unobserved potential outcomes are thus known (they are the same as the observed outcome), and we can use the randomisation distribution to easily calculate P-values. We can calculate P-values by calculating the test statistic for all possible assignments, and then calculate the probability that the test-statistic is as extreme or more extreme than the value of the test statistic we observe given the actual assignment.\n[^hypothesis] Compare this to the null hypothesis we more frequently test in experiments, namely, that there is no treatment effect on average. This later hypothesis is less strict (or sharp) than Fisher’s, but arguably of more practical interest most of the time."
  },
  {
    "objectID": "chapters/fisher.html#useful-resources",
    "href": "chapters/fisher.html#useful-resources",
    "title": "4  Fisher’s exact P-value approach",
    "section": "4.2 Useful resources",
    "text": "4.2 Useful resources\nImbens and Rubin (2015)\n\n\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press."
  },
  {
    "objectID": "chapters/fisher.html#a-simple-example",
    "href": "chapters/fisher.html#a-simple-example",
    "title": "4  Fisher’s exact P-value approach",
    "section": "4.1 A simple example",
    "text": "4.1 A simple example\nWe have a sample of six units, three assigned to treatment (\\(W_i = 1\\)) and three to control (\\(W_i = 0\\)). The first two columns in the table show the (unobserved) potential outcomes under control and treatment status, the third and fourth column show the observed treatment status and outcome. For each of the six units the outcome value we observe is the potential outcome corresponding to the treatment status.\n\n\n\n\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(W_i\\)\n\\(Y_i^{obs}\\)\n\n\n\n\n1\n?\n3\n1\n3\n\n\n2\n?\n5\n1\n5\n\n\n3\n?\n0\n1\n0\n\n\n4\n4\n?\n0\n4\n\n\n5\n0\n?\n0\n0\n\n\n6\n1\n?\n0\n1\n\n\n\nThis table highlights the fundamental problem of causal inference – we can only ever observe one potential outcome for each unit.\nHowever, Fisher’s sharp null hypothesis asserts that:\n\\[\nH_0: Y_i(1) = Y_i(0) \\quad \\text{for $i = 1, \\dots, 6$},\n\\]\nwhich makes filling in the missing values trivial:\n\n\n\n\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(W_i\\)\n\\(Y_i^{obs}\\)\n\n\n\n\n1\n(3)\n3\n1\n3\n\n\n2\n(5)\n5\n1\n5\n\n\n3\n(0)\n0\n1\n0\n\n\n4\n4\n(4)\n0\n4\n\n\n5\n0\n(0)\n0\n0\n\n\n6\n1\n(1)\n0\n1\n\n\n\nThere are a number of different test statistics we could use (and Imbens and Rubin (2015) discuss and compare an number of them). Following the book, for this example I use the absolute value of the difference in average outcome by treatment status, \\(T(W, Y^{obs}) = |\\bar{Y}_t^{obs} - \\bar{Y}_c^{obs}|\\), which is a function of the random assignment \\(W\\) and the observed values \\(Y^{obs}\\).\nFor our little experiment above, we can calculate the test statistic easily as:\n\\[\n\\begin{aligned}\nT^{obs} &= |(Y_1^{obs} + Y_2^{obs} + Y_3^{obs})/3 - (Y_4^{obs} + Y_5^{obs} + Y_6^{obs})/3| \\\\\n&= |(3 + 5 + 0)/3 - (4 + 0 + 1)/3| \\\\\n&= 8/3 - 5/3 \\\\\n&= 1\n\\end{aligned}\n\\]\nTo calculate the P-value, we need the distribution of test statistics under all possible random assignments. There are \\(\\begin{psmallmatrix}6\\\\3\\end{psmallmatrix} = 20\\) different assignments, and we can calculate the distribution using Python:\n\nimport numpy as np\nfrom itertools import combinations\nimport seaborn as sns\n\ny = np.array([3, 5, 0, 4, 0, 1])\nidx = range(len(y))\n\nts = []\nfor w in combinations(idx, 3):\n    w0, w1 = list(set(idx) - set(w)), list(w)\n    y0, y1 = y[w0], y[w1]\n    t = abs(np.mean(y1) - np.mean(y0))\n    ts.append(t)\n\nsns.histplot(ts);\n\n\n\n\nWith that distribution in hand, we can easily calculate the P-value:\n\np = np.mean([t &gt;= 1 for t in ts])\np\n\n0.5\n\n\nThe P-value indicates that if there is no treatment effect, we’d expect a value of the test statistic equal to 1 or even larger in 50 out of 100 random experiments, which does not provide any evidencen against the null hypothesis."
  },
  {
    "objectID": "chapters/neyman_rubin_causal_model.html#potential-outcomes",
    "href": "chapters/neyman_rubin_causal_model.html#potential-outcomes",
    "title": "3  Neyman-Rubin causal model",
    "section": "3.1 Potential outcomes",
    "text": "3.1 Potential outcomes"
  },
  {
    "objectID": "chapters/neyman_rubin_causal_model.html#causal-estimands",
    "href": "chapters/neyman_rubin_causal_model.html#causal-estimands",
    "title": "3  Neyman-Rubin causal model",
    "section": "3.2 Causal estimands",
    "text": "3.2 Causal estimands\n\nWe have a population of units \\(i = 1, \\dots, N\\).\nEach unit in the population can be exposed to one of two treatments, which are identical across units, so that \\(\\mathbb{T}_i = \\mathbb{T} = \\{0, 1\\}\\).\nEach unit \\(i\\) has potential outcomes \\(Y_i(0)\\) and \\(Y_i(1)\\) corresponding to each of the two possible treatments.\nUnit-level causal effects are given by comparisons of \\(Y_i(0)\\) and \\(Y_i(1)\\), often expressed as a simple difference:\n\n\\[\nY_i(1) - Y_i(0).\n\\]\n\nWe often want to summarise unit-level treatment effects, to which effect we can calculate many different causal estimands.\nThe average treatment effect over the entire population (the finite sample) is defined as:\n\n\\[\n\\tau_{fs} = \\frac{1}{N}\\sum_{i=1}^N \\left(Y_i(1) - Y_i(0)\\right).\n\\]\n\nWe can generalise this in a number of ways.\nWe can focus only on a subset of the population, which can also happen in different ways.\nWe can condition on covariates, such as when we focus only on women: \\[\n\\tau_{fs, f} = \\frac{1}{N_f}\\sum_{i: X_i = f} \\left(Y_i(1) - Y_i(0)\\right), \\quad \\text{where $X_i = \\{m , f\\}$ and $N_f = \\sum_{i=1}^N \\mathbb{1}_{X_i = f}$}\n\\]\nWe can condition on treatment status, such as when we focus only on units that were exposed to the treatment:\n\n\\[\n\\tau_{fs, t} = \\frac{1}{N_t}\\sum_{i: W_i = 1} \\left(Y_i(1) - Y_i(0)\\right), \\quad \\text{where $W_i = \\{0 , 1\\}$ and $N_t = \\sum_{i=1}^N \\mathbb{1}_{W_i = 1}$}\n\\]\n\nWe can condition on potential outcomes, such as when we focus only on units with positive potential outcomes (e.g. positive earnings) regardless of treatment status:\n\n\\[\n\\tau_{fs, pos} = \\frac{1}{N_{pos}}\\sum_{i: Y_i(0)&gt;0, Y_i(1)&gt;0} \\left(Y_i(1) - Y_i(0)\\right), \\quad \\text{where $N_{post} = \\sum_{i=1}^N \\mathbb{1}_{Y_i(0)&gt;0, Y_i(1)&gt;0}$}\n\\]\n\nWe can also generalise the estimand by focusing on more general functions of the potential outcomes (e.g. we may focus on the median outcome of the entire population or a subpopulation).\nIn all these cases, we can write the causal estimand as a row-exchangeable function (a function that takes vectors or matrices as arguments and the result of which does not change if the rows in its input are permuted):\n\n\\[\n\\tau = \\tau(Y(0), Y(1), X, W)\n\\]"
  },
  {
    "objectID": "chapters/neyman_rubin_causal_model.html#stable-unit-treatment-value-assumption",
    "href": "chapters/neyman_rubin_causal_model.html#stable-unit-treatment-value-assumption",
    "title": "3  Neyman-Rubin causal model",
    "section": "3.3 Stable unit treatment value assumption",
    "text": "3.3 Stable unit treatment value assumption"
  },
  {
    "objectID": "chapters/neyman_rubin_causal_model.html#the-assignment-mechanism",
    "href": "chapters/neyman_rubin_causal_model.html#the-assignment-mechanism",
    "title": "3  Neyman-Rubin causal model",
    "section": "3.4 The assignment mechanism",
    "text": "3.4 The assignment mechanism"
  },
  {
    "objectID": "chapters/neyman.html",
    "href": "chapters/neyman.html",
    "title": "5  Neyman’s repeated sampling approach",
    "section": "",
    "text": "In a setting with \\(i = 1, \\dots, N\\) units with fixed potential outcomes \\(Y_i(0)\\) and \\(Y_i(1)\\), where the only random component is the random assignment, captured by the assignment vector \\(W\\), Neyman was interested in the population average treatment effect:\n\\[\n\\tau_{fs} = \\frac{1}{N}\\sum_{i=1}^N \\left(Y_i(1) - Y_i(0)\\right) = \\bar{Y}(1) - \\bar{Y}(0),\n\\tag{5.1}\\]\nwhere \\(\\bar{Y}(1) = \\frac{1}{N}\\sum_{i=1}^N Y_i(1)\\) and \\(\\bar{Y}(0) = \\frac{1}{N}\\sum_{i=1}^N Y_i(0)\\). This is our estimand of interest.\nIf we have data from a completely randomised experiment in which \\(N_t = \\sum_{i=1}^N W_i\\) units are allocated to treatment and the remaining \\(N_c = \\sum_{i=1}^N (1-W_i)\\) to control, then a natural estimator for Equation 5.1 is the"
  },
  {
    "objectID": "chapters/neyman.html#footnotes",
    "href": "chapters/neyman.html#footnotes",
    "title": "5  Neyman’s repeated sampling approach",
    "section": "",
    "text": "Note that this is the same setting as in Fisher’s approach↩︎"
  },
  {
    "objectID": "chapters/neyman.html#estimator-for-the-average-treatment-effect",
    "href": "chapters/neyman.html#estimator-for-the-average-treatment-effect",
    "title": "5  Neyman’s repeated sampling approach",
    "section": "5.1 Estimator for the average treatment effect",
    "text": "5.1 Estimator for the average treatment effect\nIn a setting with \\(i = 1, \\dots, N\\) units with fixed potential outcomes \\(Y_i(0)\\) and \\(Y_i(1)\\), where the only random component is the random assignment, captured by the assignment vector \\(W\\)1, Neyman was interested in the population average treatment effect:\n\\[\n\\tau_{fs} = \\frac{1}{N}\\sum_{i=1}^N \\left(Y_i(1) - Y_i(0)\\right) = \\bar{Y}(1) - \\bar{Y}(0),\n\\tag{5.1}\\]\nwhere\n\\[\n\\bar{Y}(1) = \\frac{1}{N}\\sum_{i=1}^N Y_i(1) \\qquad \\bar{Y}(0) = \\frac{1}{N}\\sum_{i=1}^N Y_i(0).\n\\]\nThis is our estimand of interest.\nIf we have data from a completely randomised experiment in which \\(N_t = \\sum_{i=1}^N W_i\\) units are allocated to treatment and the remaining \\(N_c = \\sum_{i=1}^N (1-W_i)\\) to control, then a natural estimator for Equation 5.1 is the difference in the averages of the treatment and control units:\n\\[\n\\hat{\\tau}^{dif} = \\bar{Y}_t^{obs} - \\bar{Y}_c^{obs}.\n\\tag{5.2}\\]\nwhere\n\\[\n\\bar{Y}_t^{obs} = \\frac{1}{N_t}\\sum_{i:W_i=1} Y_i^{obs} \\qquad \\bar{Y}_c^{obs} = \\frac{1}{N_c}\\sum_{i:W_i=0} Y_i^{obs}\n\\]\nThis estimator is unbiased (see Proof of Theorem 6.1 in Imbens and Rubin (2015) for the proof)."
  },
  {
    "objectID": "chapters/neyman.html#confidence-interval-for-the-average-treatment-estimator",
    "href": "chapters/neyman.html#confidence-interval-for-the-average-treatment-estimator",
    "title": "5  Neyman’s repeated sampling approach",
    "section": "5.2 Confidence interval for the average treatment estimator",
    "text": "5.2 Confidence interval for the average treatment estimator\nNeyman was also interested in creating confidence intervals for the treatment effect estimate. This involves three steps:\n\nDerive the sampling variance of the estimator for the average treatment effect (i.e. for the estimator defined in Equation 5.2).\nDevelop estimators for this sampling variance.\nAppeal to a central limit argument for the large sample normality of \\(\\hat{\\tau}\\) over its randomisation distribution and use its estimated sampling variance from step 2 to create a large-sample confidence interval for \\(\\tau_{fs}\\).\n\n\n5.2.1 Sampling variance\nThe sampling variance of \\(\\hat{\\tau}^{dif}\\) is (see Theorem 6.2 in Imbens and Rubin (2015)):\n\\[\n\\mathbb{V}_W \\left(\\bar{Y}_t^{obs} - \\bar{Y}_c^{obs}\\right)\n= \\frac{S_c^2}{N_c} + \\frac{S_t^2}{N_t} - \\frac{S_{ct}^2}{N}\n\\tag{5.3}\\]\nwhere:\n\\[\nS_c^2 = \\frac{1}{N - 1}\\sum_{i=1}^{N}\\left(Y_i(0) - \\bar{Y}(0)\\right)^2,\n\\] \\[\nS_t^2 = \\frac{1}{N - 1}\\sum_{i=1}^{N}\\left(Y_i(1) - \\bar{Y}(1)\\right)^2,\n\\]\nand\n\\[\n\\begin{aligned}\nS_{ct}^2 &= \\frac{1}{N - 1}\\sum_{i=1}^{N}\\left(Y_i(1) - Y_i(0) - (\\bar{Y}(1) - \\bar{Y}(0))\\right)^2 \\\\\n&= \\frac{1}{N - 1}\\sum_{i=1}^{N}\\left(Y_i(1) - Y_i(0) - \\tau_{fs})\\right)^2\n\\end{aligned}\n\\]\n\n\n5.2.2 Estimator of sampling variance\nIf the unit level treatment effects \\(Y_(1) - Y_i(0)\\) are constant, then the below is an unbiased estimator for the sampling variance (see Theorem 6.3 in Imbens and Rubin (2015)):\n\\[\n\\hat{\\mathbb{V}}^{neyman} = = \\frac{s_c^2}{N_c} + \\frac{s_t^2}{N_t},\n\\]\nwhere:\n\\[\ns_c^2 = \\frac{1}{N_c - 1}\\sum_{i:W_i=0}\\left(Y_i(0) - \\bar{Y}_c^{obs}\\right)^2 \\qquad s_t^2 = \\frac{1}{N_t - 1}\\sum_{i:W_i=1}\\left(Y_i(1) - \\bar{Y}_t^{obs}\\right)^2\n\\]\n\n\n5.2.3 Confidence intervals\n\n\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press."
  },
  {
    "objectID": "chapters/stats_for_business.html",
    "href": "chapters/stats_for_business.html",
    "title": "8  Stats for business",
    "section": "",
    "text": "In some business organisations there is a prevailing wisdom that “science” often in the form of A/B testing (which is the digital version of controlled experiments) makes making decisions harder by slowing them down, which wastes important time.\nOne of the main jobs of an experimentation specialist in an organisation is to help people understand why running experiments is crucial. In this space, I want to gather my evolving thoughts on this topic with the aim of crafting an increasingly convincing argument.\nRelevant thoughts:\n\nEpistemic argument about how we know what works: human behaviour is heterogeneous and largely unpredictable, so to know what works you need to test things, and the easiest (certainly for most tech companies) and most rigorous way to test things is to run experiments.\nExperiments do not slow decision making down, but are one of the most powerful tools we have to ensure that the decisions we make are good ones.\nDiscuss when not to experiment (for there clearly are cases where you either don’t have the time or where there really is no need).\nAndrew Gelman argues (in this blog post) that i) “to reduce, control, or adjust for bias and variation in measurements” and ii) “to systematically gather data on multiple cases” are the two most important parts of statistics. This is a good way of emphasising why running experiments in a standardised way are important even if you feel you have data about your feature: it ensures that you collect data from a representative sample of users and it ensures you are judging the success of your feature by pre-defined metrics defined in a standardised way (at least ideally!).\nHow do we define identity of executives or product managers: not around knowing what is true or what works or what customers want, but around coming up with good hypotheses, being willing to learn from data, and strong at iterating on features based on data and past experience."
  },
  {
    "objectID": "chapters/neyman.html#estimator-of-the-variance-of-the-average-treatment-effect-estimator",
    "href": "chapters/neyman.html#estimator-of-the-variance-of-the-average-treatment-effect-estimator",
    "title": "5  Neyman’s repeated sampling approach",
    "section": "5.2 Estimator of the variance of the average treatment effect estimator",
    "text": "5.2 Estimator of the variance of the average treatment effect estimator\nEstimating the variance of the average treatment estimator \\(\\hat{tau}^{dif}\\) involves two steps:\n\nDerive the sampling variance of the estimator for the average treatment effect (i.e. for the estimator defined in Equation 5.2).\nDevelop estimators for this sampling variance.\n\nThe sampling variance of \\(\\hat{\\tau}^{dif}\\) is (see Theorem 6.2 in Imbens and Rubin (2015)):\n\\[\n\\mathbb{V}_W \\left(\\bar{Y}_t^{obs} - \\bar{Y}_c^{obs}\\right)\n= \\frac{S_c^2}{N_c} + \\frac{S_t^2}{N_t} - \\frac{S_{ct}^2}{N},\n\\tag{5.3}\\]\nwhere:\n$$ \\[\\begin{align}\nS_c^2 &= \\frac{1}{N - 1}\\sum_{i=1}^{N}\\left(Y_i(0) - \\bar{Y}(0)\\right)^2 \\\\\n\nS_t^2 &= \\frac{1}{N - 1}\\sum_{i=1}^{N}\\left(Y_i(1) - \\bar{Y}(1)\\right)^2 \\\\\n\nS_{ct}^2 &= \\frac{1}{N - 1}\\sum_{i=1}^{N}\\left(Y_i(1) - Y_i(0) - (\\bar{Y}(1) - \\bar{Y}(0))\\right)^2 \\\\\n\n&= \\frac{1}{N - 1}\\sum_{i=1}^{N}\\left(Y_i(1) - Y_i(0) - \\tau_{fs}\\right)^2 \\\\\n\\end{align}\\] $$\nIf the unit level treatment effects \\(Y_(1) - Y_i(0)\\) are constant, then the below is an unbiased estimator for the sampling variance (see Theorem 6.3 in Imbens and Rubin (2015)):\n\\[\n\\hat{\\mathbb{V}}^{neyman} = \\frac{s_c^2}{N_c} + \\frac{s_t^2}{N_t},\n\\tag{5.4}\\]\nwhere:\n\\[\ns_c^2 = \\frac{1}{N_c - 1}\\sum_{i:W_i=0}\\left(Y_i(0) - \\bar{Y}_c^{obs}\\right)^2 \\qquad s_t^2 = \\frac{1}{N_t - 1}\\sum_{i:W_i=1}\\left(Y_i(1) - \\bar{Y}_t^{obs}\\right)^2\n\\]\nThere are other estimators, but \\(\\hat{\\mathbb{V}}^{neyman}\\) is the most commonly used because:\n\nIt is conservative (because it ignores the last term in Equation 5.3)\nIt is always an unbiased estimator of Equation 5.3 under the super-population perspective"
  },
  {
    "objectID": "chapters/neyman.html#further-notes",
    "href": "chapters/neyman.html#further-notes",
    "title": "5  Neyman’s repeated sampling approach",
    "section": "5.3 Further notes",
    "text": "5.3 Further notes\n\nThe Neyman approach can incorporate discrete covariates by partitioning sample into subgroups, calculating subgroup treatment effects, and aggregating the subgroup treatment effects using a subgroup-size weighted average.\nHowever, it cannot handle cases where there are covariate values for which only treatment or control units are observed. In this case, we need to build a model for potential outcomes (e.g. by using regression analysis).\n\n\n\n\n\nImbens, Guido W, and Donald B Rubin. 2015. Causal Inference in Statistics, Social, and Biomedical Sciences. Cambridge University Press."
  },
  {
    "objectID": "chapters/neyman_rubin_causal_model.html#finite-sample-vs-super-population-perspective",
    "href": "chapters/neyman_rubin_causal_model.html#finite-sample-vs-super-population-perspective",
    "title": "3  Neyman-Rubin causal model",
    "section": "3.5 Finite sample vs super-population perspective",
    "text": "3.5 Finite sample vs super-population perspective\nThere are two ways to perform inference:\n\nWhen using the finite sample perspective, the \\(N\\) units in the experiment sample are treated as the entire population of interest. Hence, there is no notion of randomisation due to sampling from a larger population, and all the randomness in the outcomes is due to randomness generates by the assignment mechanism.\nWhen treating the \\(N\\) units in the sample as a random sample from a larger super-population, then in addition to randomness from the randomisation, we also have randomness from the sampling."
  },
  {
    "objectID": "chapters/cupac.html#thoughts",
    "href": "chapters/cupac.html#thoughts",
    "title": "9  CUPAC",
    "section": "9.2 Thoughts",
    "text": "9.2 Thoughts\n\nThere are two approaches: predict the experiment-time outcome or predict the pre-experiment value.\nIf you do the former, then you need features that are unaffected by the treatment. This means that for reach metric and each experiment, you need to collect features that meet this requirement. This will be different for each metric and experiment because for many features, whether or not the feature is impacted by the treatment depends on the specific experiment (i.e. where in the funnel the feature is active). This could be solved by finding, for each metric of interest, a set of features that are always independent of the treatment (such as distance between restaurant and customer, or the type of browser used by a customer), but it’s not at all clear that finding a set of features with good predictive properties is possible for all our metrics. Hence, building this into a pipeline in an automated way would be an enormous endeavour, if it’s possible at all.\nThis approach is thus really only viable in a very specialised setting where you keep running the same type of experiment, and thus have to build and train the model manually and only once (this is how it’s being used for courier experiments).\nTo ensure that features really are independent of treatment condition, they actively monitor correlations for each running experiment.\nTang et al. (2000) gives the example of reducing average daily delivery time, where a delivery-level covariate that is unaffected by treatment is distance between restaurant and customer."
  },
  {
    "objectID": "chapters/cupac.html#disadvantages",
    "href": "chapters/cupac.html#disadvantages",
    "title": "9  CUPAC",
    "section": "9.3 Disadvantages",
    "text": "9.3 Disadvantages\n\n9.3.1 Useful resources\n\nControl Using Predictions as Covariates in Switchback Experiments\n\n\n\n\n\nTang, Yixin, Caixia Huang, David Kastelman, and Jared Bauman. 2000. “Control Using Predictions as Covariates in Switchback Experiments.”"
  },
  {
    "objectID": "chapters/cupac.html#advantages",
    "href": "chapters/cupac.html#advantages",
    "title": "9  CUPAC",
    "section": "9.1 Advantages",
    "text": "9.1 Advantages\n\nCan be used for metrics that have no pre-experiment data (if you have variables that correlate with the metric and are unaffected by the treatment)"
  },
  {
    "objectID": "chapters/misc_topics.html#causal-inference-vs-prediction",
    "href": "chapters/misc_topics.html#causal-inference-vs-prediction",
    "title": "10  Miscellaneous topics",
    "section": "10.1 Causal inference vs prediction",
    "text": "10.1 Causal inference vs prediction\n\nPrediction is about finding the most likely outcome based on a set of (existing) covariates. Causal inference is about finding the effect of a change in a covariate on the outcome.\nThe difference is profound: when predicting, you take the features as a given and predict outcomes based on them – you’re asking: “given existing features, what outcome can I expect?”. When you perform causal inference, you want to know what would happen if you were to change one of the covariates – you’re asking “if I were to change one covariate in a certain way, what outcome could I expect?”.\nCausal inference is about manipulating covariates – to paraphrase Donald Rubin: there is no causality without manipulation.\nTechnically, what this really comes down to is that in prediction, you don’t care about selection bias, whereas in causal inference that’s the main thing you care about.\nThis also means that the role of goodness of fit is very different: for prediction, it’s obviously very important – if your model explains only a very small part of the variation in the outcome, it won’t be very good at predicting outcomes. In causal inference, goodness of fit doesn’t matter because your aim is not to predict, but to know how the outcome changes if you change a covariate. So, you can have very low goodness of fit (lots of things outside the model predicting outcomes), but if you can precisely estimate your treatment effect, that’s very valuable (you learn that regardless of all the many other factors that determine the outcome, changing a covariate in a certain way tends to change outcomes in a certain way.)"
  },
  {
    "objectID": "chapters/neyman_rubin_causal_model.html#stable-unit-treatment-value-assumption-sutva",
    "href": "chapters/neyman_rubin_causal_model.html#stable-unit-treatment-value-assumption-sutva",
    "title": "3  Neyman-Rubin causal model",
    "section": "3.3 Stable unit treatment value assumption (SUTVA)",
    "text": "3.3 Stable unit treatment value assumption (SUTVA)\n\nSUTVA has two components: no interference, and no hidden variations of treatments.\n\nNo interference\n\nThe no interference assumption states that a unit’s potential outcumes are independent of the treatment assignment of all other units.\nThis will be violated if there are network effects: if the behaviour of units is mutually dependent. For instance: if my wife and I both use an online photo-sharing service and my wife sees a new feature that we both like while I’m in the control group, we might stil share the same number of family photos but start sharing them all on her account instead of mine. This creates an artificial treatment effect because if I had also had access to the new feature, we might not have changed our behaviour at all, while, during the experiment, her sharing volume went up while mine went down, suggesting the existent of a positive effect.\nAnother case where the no interference assumption can be violated is in the form of general equilibrium effects. A classic example is the effect of further education: the effect of my doing a PhD in statistics on my earnings while nobody else changes their behaviour (the partial-equilibrium effect) is surely different from the outcome of my earnings if suddenly everyone decided to do a PhD in statistics (the general-equilibrium effect).\nThe two violations capture the two different ways interference can lead to incorrect results: interference can happen and bias our results either during the experiment or once the feature is fully rolled out. In either case, the treatment of some unit has an externality on other units.\n\nNo hidden treatment variations\n\nThe second component, no hidden treatment variation, states that a unit receiving a specific treatment level cannot receive different forms of that treatment level. This does not mean that the form of the treatment level has to be the same for each unit, but only that a given treatment level is well specified for a given unit. To use Imbens and Rubin’s aspirin example: suppose we test the effect of aspirin on reducing headaches but have old and new aspirins which vary in strength, so that we effectively have three possible treatment statuses: no aspirin (control), weak aspirin, and strong aspirin. SUTVA does not require that all treatment units either get the weak or the strong aspirin, but requires that each unit can only receive one or the other in case they are treated, so that there is no ambiguity what form of the treatment a given unit will receive in case it is treated. (It would be permissible to have the treatment be randomly weak or strong, but this is not relevant in my world.)\nEssentially, both parts of SUTVA ensure the same thing: that \\(Y_i(w)\\) is well defined: that it does not depend on the treatment status of other units, and that, for each possible treatment level, \\(w\\), the precise form of that treatment level is well specified."
  },
  {
    "objectID": "chapters/neyman_rubin_causal_model.html#useful-resources",
    "href": "chapters/neyman_rubin_causal_model.html#useful-resources",
    "title": "3  Neyman-Rubin causal model",
    "section": "3.6 Useful resources",
    "text": "3.6 Useful resources"
  },
  {
    "objectID": "chapters/network_experiments.html",
    "href": "chapters/network_experiments.html",
    "title": "8  Network experiments",
    "section": "",
    "text": "Network experiments are experiments where there the treatment status of units might determine the outcome of other units, thus violating the SUTVA assumption\nWays to measure the strength of interaction effects\n\nOverall approach: if there are no interaction effects, different estimands should be the same\nDesign side: run clauster and unit-level experiment side-by-side. Different results imply presence of interaction effects\nAnalysis side: 1) exposure modelling / reweighting 2) use of focal units\n\nWays to deal with interaction effects:\n\nRandomise at the level at which general-equilibrium effects play out. There are two challenges with this:\n\nFinding the appropriate level at which to randomise/cluster: effectively, you need to find the clusters between which there is no interactions, so that externalities don’t spill across cluster boundaries. Examples:\n\nGeographical clustering:\n\nto experiment on currier behaviour in a food delivery network: randomise at a level at which curriers don’t interact (such as a part of a large city, or even between cities).\nIn a online-dating network, clusters may be geographical regions between which there is little interaction between users (i.e. locations to far away for people to wanting to find partners)\n\nsocial/interaction-graph-clustering:\n\nTo test a feature in a social-network app: create graphs of user interactions, and partition the graph such that there is maximal within-group interaction and minimal between group interaction\n\n\nEnsuring you have enough effective sample size: if the outcomes of users within a group are correlated, then randomising at a level higher than the unit reduces effective sample size. In the extreme case, where within group correlation is perfect, your effective sample size is the number of groups, not the number of units.\n\nCan also measure network effects by administring different levels of the treatment (Duflo paper)"
  },
  {
    "objectID": "chapters/network_experiments.html#the-problem",
    "href": "chapters/network_experiments.html#the-problem",
    "title": "8  Network experiments",
    "section": "8.1 The problem",
    "text": "8.1 The problem\n\nInterference creates bias in standard ATE estimators.\nFundamentally, this happens because with interference, the ATE is not an estimate of what would happen if all units were treated (which is what standard ATE estimates are estimating)."
  },
  {
    "objectID": "chapters/network_experiments.html#measuring-interaction-effects",
    "href": "chapters/network_experiments.html#measuring-interaction-effects",
    "title": "8  Network experiments",
    "section": "8.4 Measuring interaction effects",
    "text": "8.4 Measuring interaction effects\n\nOverall approach: if there are no interaction effects, different estimands should be the same\nDesign side: run clauster and unit-level experiment side-by-side. Different results imply presence of interaction effects\nAnalysis side: 1) exposure modelling / reweighting 2) use of focal units"
  },
  {
    "objectID": "chapters/network_experiments.html#dealing-with-interaction-effects",
    "href": "chapters/network_experiments.html#dealing-with-interaction-effects",
    "title": "8  Network experiments",
    "section": "8.3 Dealing with interaction effects",
    "text": "8.3 Dealing with interaction effects\n\nThere are a number of different approaches (see, e.g. discussion in Larsen et al. (2023))\nWhat they share in common is that they all address the fundamental problem: that units that interact with one another are not all in the same treatment group, as they would be if everyone were in the same treatment group (as standard ATE estimaors assume).\nThere are two broad approaches: those that adjust the design, and those that adjust the analysis.\n\n\n8.3.1 Design-based approaches\n\n8.3.1.1 Cluster-based randomisation approaches\n\nThis approache first splits the units into clusters that are disjoint (or as disjoint as possible). Randomisation then happens at the cluster level, and all units within a cluster receive the same treatment.\nBecause units will interact only (or mostly) with units that have the same treatment status as they themselves, this design provides a better counterfacturals for the all-treated and all-controlled alternatives.\nOne challenge is creating clusters: effectively, you need to find the clusters between which there is no interactions, so that externalities don’t spill across cluster boundaries. Examples:\n\nGeographical clustering:\n\nto experiment on currier behaviour in a food delivery network: randomise at a level at which curriers don’t interact (such as a part of a large city, or even between cities).\nIn a online-dating network, clusters may be geographical regions between which there is little interaction between users (i.e. locations to far away for people to wanting to find partners)\n\nsocial/interaction-graph-clustering:\n\nTo test a feature in a social-network app: create graphs of user interactions, and partition the graph such that there is maximal within-group interaction and minimal between group interaction\n\n\nAnother challenge is ensuring you have enough effective sample size: if the outcomes of users within a group are correlated, then randomising at a level higher than the unit reduces effective sample size. In the extreme case, where within group correlation is perfect, your effective sample size is the number of groups, not the number of units.\n\n\n\n8.3.1.2 Ego-clusters\n\nInstead of traditional clusters, create much smaller, unit-based clusters.\n\n\n\n8.3.1.3 Switchback experiments\n\nAn approach often used to deal with marketplace interferance, whereby all units are frequently switched from being in control to being in treatment.\nThere could be carry-over issues with this, but this can be dealt with by using “burn-in” periods.\nAnother issue is that, like cluster-randomisation, switchbacks also suffer from lower power.\n\n\n\n\n8.3.2 Analysis-based approaches\n\nAnalysis based approaches model the interference and then adjust the analysis accordingly. See last paragraph of section 6 in Larsen et al. (2023) for details."
  },
  {
    "objectID": "chapters/network_experiments.html#approaches-in-practice",
    "href": "chapters/network_experiments.html#approaches-in-practice",
    "title": "8  Network experiments",
    "section": "8.4 Approaches in practice",
    "text": "8.4 Approaches in practice\n\nKarrer et al. (2021) describe network experimentation at Meta\n\n\n\n\n\nKarrer, Brian, Liang Shi, Monica Bhole, Matt Goldman, Tyrone Palmer, Charlie Gelman, Mikael Konutgan, and Feng Sun. 2021. “Network Experimentation at Scale.” In Proceedings of the 27th Acm Sigkdd Conference on Knowledge Discovery & Data Mining, 3106–16."
  },
  {
    "objectID": "chapters/network_experiments.html#types-of-interferance",
    "href": "chapters/network_experiments.html#types-of-interferance",
    "title": "8  Network experiments",
    "section": "8.2 Types of interferance",
    "text": "8.2 Types of interferance\nLarsen et al. (2023) differentiate between:\n\nNetwork interference: all units in the population are the same but they interact with each other. In particular, interference happens when the treatment status of users in a social network mutually determines their outcome (e.g. one user being assigned to a new messenger service might increase messaging for that individual’s friends who are in control)\nMarketplace interference: there are at least two types of units that form an online marketplace (i.e. sellers and buyers), and interference often happens when units compete for finite resources (e.g. uber customers hailing a finite amount of drivers, JET restaurants relying on a finite number of drivers). Examples are ride hailing, job matching, ads marketplaces, education platforms, and food delivery, which is an example of a three-sided marketplace.\nA particular typs of interference is “cannibalisation”, whereby the increase in the desired behaviour in the treatment group is solely or (under partial cannibalisation) partially due to a shift of the behaviour from control units to treatment units. This usually happens if units share a common pool of a fixed resource (e.g. a fixe number of uber drivers, a fixed number of items to buy at an auction) and the treatment makes it easier or more attractive for the treatment units to engage in the behaviour, which then leaves fewer resources to the control. In other words, it’s in zero-sum contexts. See Liu, Mao, and Kang (2020)"
  },
  {
    "objectID": "chapters/network_experiments.html#useful-resources",
    "href": "chapters/network_experiments.html#useful-resources",
    "title": "8  Network experiments",
    "section": "8.5 Useful resources",
    "text": "8.5 Useful resources\n\nLarsen et al. (2023), in section 6, provides a recent review of the literature.\nKarrer et al. (2021) describe network experimentation at Meta.\n\n\n\n\n\nKarrer, Brian, Liang Shi, Monica Bhole, Matt Goldman, Tyrone Palmer, Charlie Gelman, Mikael Konutgan, and Feng Sun. 2021. “Network Experimentation at Scale.” In Proceedings of the 27th Acm Sigkdd Conference on Knowledge Discovery & Data Mining, 3106–16.\n\n\nLarsen, Nicholas, Jonathan Stallrich, Srijan Sengupta, Alex Deng, Ron Kohavi, and Nathaniel T Stevens. 2023. “Statistical Challenges in Online Controlled Experiments: A Review of a/b Testing Methodology.” The American Statistician, 1–15.\n\n\nLiu, Min, Jialiang Mao, and Kang Kang. 2020. “Trustworthy Online Marketplace Experimentation with Budget-Split Design.” arXiv Preprint arXiv:2012.08724."
  }
]